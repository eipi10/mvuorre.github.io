<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models</title>

<meta property="description" itemprop="description" content="Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here."/>

<link rel="canonical" href="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2017-10-09"/>
<meta property="article:created" itemprop="dateCreated" content="2017-10-09"/>
<meta name="article:author" content="Matti Vuorre"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here."/>
<meta property="og:url" content="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"/>
<meta property="og:image" content="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot-1.png"/>
<meta property="og:image:width" content="1248"/>
<meta property="og:image:height" content="768"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Statistics and Data Science Tutorials"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models"/>
<meta property="twitter:description" content="Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here."/>
<meta property="twitter:url" content="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"/>
<meta property="twitter:image" content="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot-1.png"/>
<meta property="twitter:image:width" content="1248"/>
<meta property="twitter:image:height" content="768"/>
<meta property="twitter:site" content="@vuorre"/>
<meta property="twitter:creator" content="@vuorre"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models"/>
<meta name="citation_fulltext_html_url" content="https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2017/10/09"/>
<meta name="citation_publication_date" content="2017/10/09"/>
<meta name="citation_author" content="Matti Vuorre"/>
<meta name="citation_author_institution" content="University of Oxford"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Intensive longitudinal methods: An introduction to diary and experience sampling research;citation_publication_date=2013;citation_publisher=Guilford Press;citation_author=Niall Bolger;citation_author=Jean-Philippe Laurenceau"/>
  <meta name="citation_reference" content="citation_title=Statistical rethinking: A bayesian course with examples in r and stan;citation_publication_date=2016;citation_publisher=CRC Press;citation_author=Richard McElreath"/>
  <meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;citation_publication_date=2017;citation_publisher=R Foundation for Statistical Computing;citation_author=R: A language and environment for statistical computing"/>
  <meta name="citation_reference" content="citation_title=Data Analysis Using Regression and Multilevel/Hierarchical Models;citation_publication_date=2007;citation_publisher=Cambridge University Press;citation_author=Andrew Gelman;citation_author=Jennifer Hill"/>
  <meta name="citation_reference" content="citation_title=Bayesplot: Plotting for Bayesian models;citation_publication_date=2017;citation_author=Jonah Gabry"/>
  <meta name="citation_reference" content="citation_title=An introduction to Bayesian hierarchical models with an application in the theory of signal detection;citation_publication_date=2005;citation_volume=12;citation_doi=10.3758/BF03196750;citation_issn=1069-9384, 1531-5320;citation_author=Jeffrey N. Rouder;citation_author=Jun Lu"/>
  <meta name="citation_reference" content="citation_title=Signal Detection Models with Random Participant and Item Effects;citation_publication_date=2007;citation_volume=72;citation_doi=10.1007/s11336-005-1350-6;citation_issn=0033-3123, 1860-0980;citation_author=Jeffrey N. Rouder;citation_author=Jun Lu;citation_author=Dongchu Sun;citation_author=Paul Speckman;citation_author=Richard D. Morey;citation_author=Moshe Naveh-Benjamin"/>
  <meta name="citation_reference" content="citation_title=Signal detection theory and generalized linear models;citation_publication_date=1998;citation_volume=3;citation_doi=10.1037/1082-989X.3.2.186;citation_issn=1939-1463 1082-989X;citation_author=Lawrence T. DeCarlo"/>
  <meta name="citation_reference" content="citation_title=Brms: An R Package for Bayesian Multilevel Models Using Stan;citation_publication_date=2017;citation_volume=80;citation_doi=10.18637/jss.v080.i01;citation_author=Paul-Christian Bürkner"/>
  <meta name="citation_reference" content="citation_title=Sdtalt: Signal detection theory and alternatives;citation_publication_date=2011;citation_author=Daniel B. Wright"/>
  <meta name="citation_reference" content="citation_title=Manipulating power can affect memory conformity;citation_publication_date=2008;citation_volume=22;citation_doi=10.1002/acp.1353;citation_issn=1099-0720;citation_author=Elin M. Skagerberg;citation_author=Daniel B. Wright"/>
  <meta name="citation_reference" content="citation_title=Calculation of signal detection theory measures;citation_publication_date=1999;citation_volume=31;citation_author=Harold Stanislaw;citation_author=Natasha Todorov"/>
  <meta name="citation_reference" content="citation_title=On the statistical and theoretical basis of signal detection theory and extensions: Unequal variance, random coefficient, and mixture models;citation_publication_date=2010;citation_volume=54;citation_doi=10.1016/j.jmp.2010.01.001;citation_issn=0022-2496;citation_author=Lawrence T. DeCarlo"/>
  <meta name="citation_reference" content="citation_title=Examining the causes of memory strength variability: Recollection, attention failure, or encoding variability?;citation_publication_date=2013;citation_volume=39;citation_doi=10.1037/a0033671;citation_issn=1939-1285(Electronic),0278-7393(Print);citation_author=Joshua D. Koen;citation_author=Mariam Aly;citation_author=Wei-Chun Wang;citation_author=Andrew P. Yonelinas"/>
  <meta name="citation_reference" content="citation_title=Detection theory: A user’s guide;citation_publication_date=2005;citation_publisher=Lawrence Erlbaum Associates;citation_author=Neil A. Macmillan;citation_author=C. Douglas Creelman"/>
  <meta name="citation_reference" content="citation_title=Using the PLUM procedure of SPSS to fit unequal variance and generalized signal detection models;citation_publication_date=2003;citation_volume=35;citation_doi=10.3758/BF03195496;citation_issn=0743-3808, 1532-5970;citation_author=Lawrence T. Decarlo"/>
  <meta name="citation_reference" content="citation_title=MPTinR: Analysis of multinomial processing tree models in R;citation_publication_date=2013;citation_volume=45;citation_doi=10.3758/s13428-012-0259-0;citation_author=Henrik Singmann;citation_author=David Kellen"/>
  <meta name="citation_reference" content="citation_title=Ggridges: Ridgeline Plots in ’Ggplot2’;citation_publication_date=2017;citation_author=Claus O. Wilke"/>
  <meta name="citation_reference" content="citation_title=The problem of inference from curves based on group data;citation_publication_date=1956;citation_volume=53;citation_doi=10.1037/h0045156;citation_issn=1939-1455(Electronic);0033-2909(Print);citation_author=W. K. Estes"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","date","categories","bibliography","output","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Bayesian Estimation of Signal Detection Models"]},{"type":"character","attributes":{},"value":["Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url","orcid_id"]}},"value":[{"type":"character","attributes":{},"value":["Matti Vuorre"]},{"type":"character","attributes":{},"value":["https://vuorre.netlify.com"]},{"type":"character","attributes":{},"value":["University of Oxford"]},{"type":"character","attributes":{},"value":["https://www.oii.ox.ac.uk/people/matti-vuorre/"]},{"type":"character","attributes":{},"value":["0000-0001-5052-066X"]}]}]},{"type":"character","attributes":{},"value":["2017-10-09"]},{"type":"character","attributes":{},"value":["psychology","statistics","tutorial","R","brms"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","toc_depth"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[4]}]}]},{"type":"character","attributes":{},"value":["https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"]},{"type":"character","attributes":{},"value":["https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/anchor-4.2.2/anchor.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/bowser-1.9.3/bowser.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/distill-2.2.21/template.v2.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot2-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt_glmm-viz1-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt_glmm-viz2-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt-glmm-viz1-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt-glmm-viz2-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fit1-plot-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fit2-plot-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fitglmm-viz1-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fitglmm-viz2-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/population-density-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/population-density2-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/scatterplot-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/sdtplot-1-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/side-by-side-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/unnamed-chunk-26-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/unnamed-chunk-28-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/unnamed-chunk-29-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/uvsdt-densityplot-1.png","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/header-attrs-2.7.1/header-attrs.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/jquery-1.11.3/jquery.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/popper-2.6.0/popper.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/tippy-6.2.7/tippy-bundle.umd.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/tippy-6.2.7/tippy-light-border.css","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/tippy-6.2.7/tippy.css","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/tippy-6.2.7/tippy.umd.min.js","2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/webcomponents-2.0.0/webcomponents.js","bibliography.bib"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<style type="text/css">
/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */



html {
  /*-- Main font sizes --*/
  --title-size:      50px;
  --body-size:       1.06rem;
  --code-size:       14px;
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --header-color:    rgba(0, 0, 0, 0.8);
  --body-color:      rgba(0, 0, 0, 0.8);
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    sans-serif;
  --mono-font:       monospace;
  --body-font:       sans-serif;
  --navbar-font:     sans-serif;  /* websites + blogs only */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.8em;
  --text-color:      rgba(0, 0, 0, 0.5);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       18px;
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

/*-- Additional custom styles --*/
/* Add any additional CSS rules below                      */
</style>
<style type="text/css">
/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */
@import url('https://fonts.googleapis.com/css2?family=Fira+Code&family=Roboto&display=swap');

html {
  /*-- Main font sizes --*/
  --title-size:      32px;
  --body-size:       1.06rem;
  --code-size:       14px;
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --header-color:    rgba(0, 0, 0, 0.8);
  --body-color:      rgba(0, 0, 0, 0.8);
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    "Roboto", sans-serif;
  --mono-font:       "Fira Code", monospace;
  --body-font:       "Roboto", sans-serif;
  --navbar-font:     "Roboto", sans-serif;  /* websites + blogs only */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.85em;
  --text-color:      rgba(0, 0, 0, 0.6);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       18px;
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      #34A5DA;
  --bkgd-color:       #222222;
  border-bottom: 4px solid #34A5DA;
  webkit-box-shadow: 1px 1px 18px #4d4d4d;
  moz-box-shadow: 1px 1px 18px #4d4d4d;
  box-shadow: 1px 1px 18px #4d4d4d;
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

/*-- Additional custom styles --*/

/* Underline links with accent color */
d-article a {
  border-bottom: 1px solid #34A5DA;
}
d-article a:hover {
  border-bottom: 2px solid #34A5DA;
}
.d-contents nav a:hover {
    text-decoration: none;
}
.categories li > a:hover {
    border-bottom: 2px solid #34A5DA;
}

/* Use accent color for decoration */
d-article div.sourceCode pre {
    border-left: 2px solid #34A5DA;
}
d-article blockquote {
    border-left: 2px solid #34A5DA;
}

/* Adjust fonts */
d-article h2 {
  line-height: 1.15em;
  font-size: 26px;
}
code {
  font-family: var(--mono-font);
  font-size: 14px;
}</style>
<style type="text/css">
/* base style */

/* FONT FAMILIES */

:root {
  --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

body,
.posts-list .post-preview p,
.posts-list .description p {
  font-family: var(--body-font), var(--body-default);
}

h1, h2, h3, h4, h5, h6,
.posts-list .post-preview h2,
.posts-list .description h2 {
  font-family: var(--heading-font), var(--heading-default);
}

d-article div.sourceCode code,
d-article pre code {
  font-family: var(--mono-font), var(--mono-default);
}


/*-- TITLE --*/
d-title h1,
.posts-list > h1 {
  color: var(--title-color, black);
}

d-title h1 {
  font-size: var(--title-size, 50px);
}

/*-- HEADERS --*/
d-article h1,
d-article h2,
d-article h3,
d-article h4,
d-article h5,
d-article h6 {
  color: var(--header-color, rgba(0, 0, 0, 0.8));
}

/*-- BODY --*/
d-article > p,  /* only text inside of <p> tags */
d-article > ul, /* lists */
d-article > ol {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
  font-size: var(--body-size, 1.06rem);
}


/*-- CODE --*/
d-article div.sourceCode code,
d-article pre code {
  font-size: var(--code-size, 14px);
}

/*-- ASIDE --*/
d-article aside {
  font-size: var(--aside-size, 12px);
  color: var(--aside-color, rgba(0, 0, 0, 0.6));
}

/*-- FIGURE CAPTIONS --*/
figure .caption,
figure figcaption,
.figure .caption {
  font-size: var(--fig-cap-size, 13px);
  color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
}

/*-- METADATA --*/
d-byline h3 {
  font-size: var(--heading-size, 0.6rem);
  color: var(--heading-color, rgba(0, 0, 0, 0.5));
}

d-byline {
  font-size: var(--body-size, 0.8rem);
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

d-byline a,
d-article d-byline a {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

/*-- TABLE OF CONTENTS --*/
.d-contents nav h3 {
  font-size: var(--heading-size, 18px);
}

.d-contents nav a {
  font-size: var(--contents-size, 13px);
}

/*-- APPENDIX --*/
d-appendix h3 {
  font-size: var(--heading-size, 15px);
  color: var(--heading-color, rgba(0, 0, 0, 0.65));
}

d-appendix {
  font-size: var(--text-size, 0.8em);
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

d-appendix d-footnote-list a.footnote-backlink {
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

/*-- WEBSITE HEADER + FOOTER --*/
.distill-site-header .title {
  font-size: var(--title-size, 18px);
  font-family: var(--navbar-font), var(--heading-default);
}

.distill-site-header a,
.nav-dropdown .nav-dropbtn {
  font-family: var(--navbar-font), var(--heading-default);
}

.nav-dropdown .nav-dropbtn {
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  font-size: var(--text-size, 15px);
}

.distill-site-header a:hover,
.nav-dropdown:hover .nav-dropbtn {
  color: var(--hover-color, white);
}

.distill-site-header {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer a:hover {
  color: var(--hover-color, white);
}</style>
<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.7.2/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=G-NKV51FTEH8"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-NKV51FTEH8');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Bayesian Estimation of Signal Detection Models","description":"Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here.","authors":[{"author":"Matti Vuorre","authorURL":"https://vuorre.netlify.com","affiliation":"University of Oxford","affiliationURL":"https://www.oii.ox.ac.uk/people/matti-vuorre/","orcidID":"0000-0001-5052-066X"}],"publishedDate":"2017-10-09T00:00:00.000+00:00","citationText":"Vuorre, 2017"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">Statistics and Data Science Tutorials</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="https://github.com/mvuorre/mvuorre.github.io" aria-label="Link to source">
<i class="fab fa-github" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Bayesian Estimation of Signal Detection Models</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:psychology" class="dt-tag">psychology</a>
  <a href="../../index.html#category:statistics" class="dt-tag">statistics</a>
  <a href="../../index.html#category:tutorial" class="dt-tag">tutorial</a>
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:brms" class="dt-tag">brms</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>Signal Detection Theory (SDT) is a popular theoretical framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are illustrated here.</p></p>
</div>

<div class="d-byline">
  Matti Vuorre <a href="https://vuorre.netlify.com" class="uri">https://vuorre.netlify.com</a> (University of Oxford)<a href="https://www.oii.ox.ac.uk/people/matti-vuorre/" class="uri">https://www.oii.ox.ac.uk/people/matti-vuorre/</a>
  
<br/>2017-10-09
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#signal-detection-theory">Signal Detection Theory</a>
<ul>
<li><a href="#example-data">Example data</a></li>
</ul></li>
<li><a href="#equal-variance-gaussian-sdt-model">Equal Variance Gaussian SDT Model</a>
<ul>
<li><a href="#calculate-evsdt-parameters-point-estimates">Calculate EVSDT parameters’ point estimates</a></li>
<li><a href="#estimate-evsdt-model-with-a-glm">Estimate EVSDT model with a GLM</a></li>
<li><a href="#estimate-evsdt-with-a-nonlinear-model">Estimate EVSDT with a nonlinear model</a></li>
<li><a href="#interim-discussion">Interim discussion</a>
<ul>
<li><a href="#fitting-one-subjects-evsdt-model-with-different-methods">Fitting one subject’s EVSDT model with different methods</a></li>
<li><a href="#prior-distribution">Prior distribution</a></li>
</ul></li>
</ul></li>
<li><a href="#evsdt-for-multiple-participants">EVSDT for multiple participants</a>
<ul>
<li><a href="#population-level-evsdt-model">Population-level EVSDT Model</a>
<ul>
<li><a href="#estimation-by-summarizing-subjects-point-estimates">Estimation by summarizing subjects’ point estimates</a></li>
<li><a href="#estimation-with-a-hierarchical-model-glmm">Estimation with a hierarchical model (GLMM)</a></li>
<li><a href="#including-predictors">Including predictors</a></li>
<li><a href="#estimation-with-a-glmm-nonlinear-syntax">Estimation with a GLMM (nonlinear syntax)</a></li>
</ul></li>
<li><a href="#interim-discussion-1">Interim discussion</a></li>
</ul></li>
<li><a href="#unequal-variance-gaussian-sdt-model">Unequal variance Gaussian SDT model</a>
<ul>
<li><a href="#example-data-rating-task">Example data: Rating task</a></li>
<li><a href="#evsdt-one-subjects-rating-responses">EVSDT: one subject’s rating responses</a></li>
<li><a href="#uvsdt-one-subjects-rating-responses">UVSDT: one subject’s rating responses</a></li>
</ul></li>
<li><a href="#uvsdt-for-multiple-participants">UVSDT for multiple participants</a>
<ul>
<li><a href="#example-data-set">Example data set</a></li>
<li><a href="#model-syntax">Model syntax</a></li>
<li><a href="#prior-distributions">Prior distributions</a></li>
<li><a href="#estimate-and-summarise-parameters">Estimate and summarise parameters</a>
<ul>
<li><a href="#heterogeneity-parameters">Heterogeneity parameters</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a>
<ul>
<li><a href="#support-this-work">Support this work</a></li>
<li><a href="#software-used">Software used</a></li>
</ul></li>
</ul>
</nav>
</div>
<h2 id="signal-detection-theory">Signal Detection Theory</h2>
<p>Signal Detection Theory (SDT) is a common framework for modeling memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are sometimes difficult to implement in practice. In this tutorial, I describe how to estimate equal and unequal variance Gaussian SDT models as Generalized Linear Models for single participants, and for multiple participants simultaneously using hierarchical Bayesian models (or Generalized Linear Mixed Models).</p>
<p>Consider a recognition memory experiment where participants are shown a series of images, some of which are new (participant has not seen before) and some of which are old (participant has seen before). Participants answer, for each item, whether they think they have seen the item before (“old!” response) or not (“new!” response). SDT models allow modeling participants’ sensitivity—how well they can distinguish new and old images—and response criterion—their tendency of <em>bias</em> to respond “old!”—separately, and can therefore be enormously useful in modeling the participants’ memory processes. This similar logic applies to e.g. perception, where SDT was initially introduced in.</p>
<p>The conceptual basis of SDT models is that on each trial, when a stimulus is presented, participants experience some inner “familiarity” (or memory strength) signal, which is hidden from the experimenter, or <em>latent</em>. The participants then decide, based on this familiarity signal, whether they have encountered the current stimulus stimulus previously (“old!”) or not (“new!”). I assume that readers are at least somewhat familiar with the basics of SDT, and will not discuss the underlying theory further. A classic introduction to the topic is <span class="citation" data-cites="macmillan_detection_2005"><a href="#ref-macmillan_detection_2005" role="doc-biblioref">Macmillan and Creelman</a> (<a href="#ref-macmillan_detection_2005" role="doc-biblioref">2005</a>)</span>.</p>
<h3 id="example-data">Example data</h3>
<p>We move on to examining a practical example using the R statistical programming environment <span class="citation" data-cites="r_core_team_r:_2017">(<a href="#ref-r_core_team_r:_2017" role="doc-biblioref">R Core Team 2017</a>)</span>. The following R packages were used in this tutorial:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://yihui.org/knitr/'>knitr</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://scales.r-lib.org'>scales</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://mc-stan.org/bayesplot/'>bayesplot</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://wilkelab.org/ggridges/'>ggridges</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>sdtalt</span><span class='op'>)</span>  <span class='co'># devtools::install_github("cran/sdtalt") (not on CRAN)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/paul-buerkner/brms'>brms</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The example data is called <code>confcontr</code>, and is provided as a data frame in the sdtalt package <span class="citation" data-cites="wright_sdtalt:_2011">(<a href="#ref-wright_sdtalt:_2011" role="doc-biblioref">Wright 2011a</a>)</span>: “These are the data from the control group in Skagerberg and Wright’s study of memory conformity. Basically, this is the simplest old/new recognition memory design.” <span class="citation" data-cites="skagerberg_manipulating_2008">(<a href="#ref-skagerberg_manipulating_2008" role="doc-biblioref">Skagerberg and Wright 2008</a>)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>confcontr</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Example recognition memory data</caption>
<thead>
<tr class="header">
<th style="text-align: right;">subno</th>
<th style="text-align: right;">sayold</th>
<th style="text-align: right;">isold</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
<h2 id="equal-variance-gaussian-sdt-model">Equal Variance Gaussian SDT Model</h2>
<p>We consider the most common SDT model, that assumes the participants’ distributions of familiarity are two Gaussian distributions with equal variances, but possibly different means (i.e. previously seen items elicit a stronger familiarity signal, on average). This model is known as the EVSDT (equal variance SDT) model.</p>
<p>We estimate the model’s parameters for a single participant using three methods: “Manual” calculation of the point estimates using easy formulas translated to R code; estimating the model using a Bayesian Generalized Linear Model; and estimating the model using a Bayesian nonlinear model.</p>
<h3 id="calculate-evsdt-parameters-point-estimates">Calculate EVSDT parameters’ point estimates</h3>
<p>We begin by calculating the maximum likelihood estimates of the EVSDT parameters, separately for each participant in the data set. Before doing so, I note that this data processing is only required for manual calculation of the point estimates; the modeling methods described below take the raw data and therefore don’t require this step.</p>
<p>First, we’ll compute for each trial whether the participant’s response was a hit, false alarm, correct rejection, or a miss. We’ll do this by creating a new variable, <code>type</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>sdt</span> <span class='op'>&lt;-</span> <span class='va'>confcontr</span> <span class='op'>%&gt;%</span>
  <span class='fu'>mutate</span><span class='op'>(</span>
    type <span class='op'>=</span> <span class='st'>"hit"</span>,
    type <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>isold</span> <span class='op'>==</span> <span class='fl'>1</span> <span class='op'>&amp;</span> <span class='va'>sayold</span> <span class='op'>==</span> <span class='fl'>0</span>, <span class='st'>"miss"</span>, <span class='va'>type</span><span class='op'>)</span>,
    type <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>isold</span> <span class='op'>==</span> <span class='fl'>0</span> <span class='op'>&amp;</span> <span class='va'>sayold</span> <span class='op'>==</span> <span class='fl'>0</span>, <span class='st'>"cr"</span>, <span class='va'>type</span><span class='op'>)</span>, <span class='co'># Correct rejection</span>
    type <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>isold</span> <span class='op'>==</span> <span class='fl'>0</span> <span class='op'>&amp;</span> <span class='va'>sayold</span> <span class='op'>==</span> <span class='fl'>1</span>, <span class='st'>"fa"</span>, <span class='va'>type</span><span class='op'>)</span> <span class='co'># False alarm</span>
  <span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Then we can simply count the numbers of these four types of trials for each participant, and put the counts on one row per participant.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>sdt</span> <span class='op'>&lt;-</span> <span class='va'>sdt</span> <span class='op'>%&gt;%</span>
  <span class='fu'>group_by</span><span class='op'>(</span><span class='va'>subno</span>, <span class='va'>type</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>summarise</span><span class='op'>(</span>count <span class='op'>=</span> <span class='fu'>n</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>spread</span><span class='op'>(</span><span class='va'>type</span>, <span class='va'>count</span><span class='op'>)</span> <span class='co'># Format data to one row per person</span>
</code></pre>
</div>
</div>
<p>For a single subject, <em>d’</em> can be calculated as the difference of the standardized hit and false alarm rates <span class="citation" data-cites="stanislaw_calculation_1999">(<a href="#ref-stanislaw_calculation_1999" role="doc-biblioref">Stanislaw and Todorov 1999</a>)</span>:</p>
<p><span class="math display">\[d&#39; = \Phi^{-1}(HR) - \Phi^{-1}(FAR)\]</span></p>
<p><span class="math inline">\(\Phi\)</span> is the cumulative normal density function, and is used to convert <em>z</em> scores into probabilities. Its inverse, <span class="math inline">\(\Phi^{-1}\)</span>, converts a proportion (such as a hit rate or false alarm rate) into a <em>z</em> score. From here on, I refer to standardized hit and false alarm rates as <em>zHR</em> and <em>zFAR</em>, respectively. The response criterion <em>c</em> is given by the negative standardized false alarm rate -<em>zFAR</em> <span class="citation" data-cites="decarlo_signal_1998">(<a href="#ref-decarlo_signal_1998" role="doc-biblioref">DeCarlo 1998</a>)</span>.</p>
<p>We can use R’s proportion to z-score function (<span class="math inline">\(\Phi^{-1}\)</span>), <code>qnorm()</code>, to calculate each participant’s <em>d’</em> and <em>c</em> from the counts of hits, false alarms, misses and correct rejections:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>sdt</span> <span class='op'>&lt;-</span> <span class='va'>sdt</span> <span class='op'>%&gt;%</span>
  <span class='fu'>mutate</span><span class='op'>(</span>
    zhr <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>qnorm</a></span><span class='op'>(</span><span class='va'>hit</span> <span class='op'>/</span> <span class='op'>(</span><span class='va'>hit</span> <span class='op'>+</span> <span class='va'>miss</span><span class='op'>)</span><span class='op'>)</span>,
    zfa <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>qnorm</a></span><span class='op'>(</span><span class='va'>fa</span> <span class='op'>/</span> <span class='op'>(</span><span class='va'>fa</span> <span class='op'>+</span> <span class='va'>cr</span><span class='op'>)</span><span class='op'>)</span>,
    dprime <span class='op'>=</span> <span class='va'>zhr</span> <span class='op'>-</span> <span class='va'>zfa</span>,
    crit <span class='op'>=</span> <span class='op'>-</span><span class='va'>zfa</span>
  <span class='op'>)</span>
</code></pre>
</div>
<table>
<caption><span id="tab:sdtcalc-3">Table 2: </span>Point estimates of EVSDT parameters</caption>
<thead>
<tr class="header">
<th style="text-align: right;">subno</th>
<th style="text-align: right;">cr</th>
<th style="text-align: right;">fa</th>
<th style="text-align: right;">hit</th>
<th style="text-align: right;">miss</th>
<th style="text-align: right;">zhr</th>
<th style="text-align: right;">zfa</th>
<th style="text-align: right;">dprime</th>
<th style="text-align: right;">crit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">53</td>
<td style="text-align: right;">33</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">22</td>
<td style="text-align: right;">0.08</td>
<td style="text-align: right;">-0.31</td>
<td style="text-align: right;">0.39</td>
<td style="text-align: right;">0.31</td>
</tr>
<tr class="even">
<td style="text-align: right;">54</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">-0.63</td>
<td style="text-align: right;">0.87</td>
<td style="text-align: right;">0.63</td>
</tr>
<tr class="odd">
<td style="text-align: right;">55</td>
<td style="text-align: right;">36</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">31</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">0.41</td>
<td style="text-align: right;">-0.47</td>
<td style="text-align: right;">0.88</td>
<td style="text-align: right;">0.47</td>
</tr>
<tr class="even">
<td style="text-align: right;">56</td>
<td style="text-align: right;">43</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0.87</td>
<td style="text-align: right;">-0.88</td>
<td style="text-align: right;">1.76</td>
<td style="text-align: right;">0.88</td>
</tr>
<tr class="odd">
<td style="text-align: right;">57</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0.30</td>
<td style="text-align: right;">-0.41</td>
<td style="text-align: right;">0.71</td>
<td style="text-align: right;">0.41</td>
</tr>
<tr class="even">
<td style="text-align: right;">58</td>
<td style="text-align: right;">41</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">30</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0.35</td>
<td style="text-align: right;">-0.75</td>
<td style="text-align: right;">1.10</td>
<td style="text-align: right;">0.75</td>
</tr>
</tbody>
</table>
</div>
<p>This data frame now has point estimates of every participant’s <em>d’</em> and <em>c</em>. The implied EVSDT model for participant 53 is shown in Figure <a href="#fig:sdtplot-1">1</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:sdtplot-1"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/sdtplot-1-1.png" alt="The equal variance Gaussian signal detection model for the first participant in the data, based on manual calculation of the parameter's point estimates. The two distributions are the noise distribution (dashed) and the signal distribution (solid); the dotted vertical line represents the response criterion. d' is the distance between the peaks of the two distributions." width="624" />
<p class="caption">
Figure 1: The equal variance Gaussian signal detection model for the first participant in the data, based on manual calculation of the parameter’s point estimates. The two distributions are the noise distribution (dashed) and the signal distribution (solid); the dotted vertical line represents the response criterion. d’ is the distance between the peaks of the two distributions.
</p>
</div>
</div>
<h3 id="estimate-evsdt-model-with-a-glm">Estimate EVSDT model with a GLM</h3>
<p>Generalized Linear Models (GLM) are a powerful class of regression models that allow modeling binary outcomes, such as our “old!” / “new!” responses. In <code>confcontr</code>, each row (trial) can have one of two responses, “old!” (<code>sayold = 1</code>) or “new!” (<code>sayold = 0</code>). We use GLM to regress these responses on the stimulus type: On each trial, the to-be-judged stimulus can be either new (<code>isold = 0</code>) or old (<code>isold = 1</code>).</p>
<p>In a GLM of binary outcomes, we assume that the outcomes are Bernoulli distributed (binomial with 1 trial), with probability <span class="math inline">\(p_i\)</span> that <span class="math inline">\(y_i = 1\)</span>.</p>
<p><span class="math display">\[y_i \sim Bernoulli(p_i)\]</span></p>
<p>Because probabilities have upper and lower bounds at 1 and 0, and we wish to use a linear model (generalized <em>linear</em> model) of the <em>p</em> parameter, we don’t model <em>p</em> with a linear model. Instead, we map <em>p</em> to a “linear predictor” <span class="math inline">\(\eta\)</span> with a link function, and model <span class="math inline">\(\eta\)</span> with a linear regression model. If this link function is probit, we have a “probit GLM”:</p>
<aside>
You are probably familiar with logistic regression models, which are just another binary GLM, but with the logistic link function!
</aside>
<p><span class="math display">\[p_i = \Phi(\eta_i)\]</span></p>
<p><span class="math inline">\(\Phi\)</span> is again the cumulative normal density function and maps <em>z</em> scores to probabilities. We then model <span class="math inline">\(\eta\)</span> on an intercept and a slope:</p>
<p><span class="math display">\[\eta_i = \beta_0 + \beta_1\mbox{isold}_i\]</span></p>
<p>Given this parameterization, the intercept of the model (<span class="math inline">\(\beta_0\)</span>) is going to be the standardized false alarm rate (probability of saying 1 when predictor is 0), which we take as our criterion <em>c</em>. The slope of the model is the increase in the probability of saying 1 when the predictor is 1, in <em>z</em>-scores, which is another way of saying <em>d’</em>. Therefore, <span class="math inline">\(c = -zHR = -\beta_0\)</span>, and <span class="math inline">\(d&#39; = \beta_1\)</span>.</p>
<p>The connection between SDT models and GLM is discussed in detail by <span class="citation" data-cites="decarlo_signal_1998"><a href="#ref-decarlo_signal_1998" role="doc-biblioref">DeCarlo</a> (<a href="#ref-decarlo_signal_1998" role="doc-biblioref">1998</a>)</span>. Two immediate benefits of thinking about SDT models in a GLM framework is that we can now easily include predictors on <em>c</em> and <em>d’</em>, and estimate SDT models with varying coefficients using hierarchical modeling methods <span class="citation" data-cites="decarlo_statistical_2010 rouder_introduction_2005">(<a href="#ref-decarlo_statistical_2010" role="doc-biblioref">DeCarlo 2010</a>; <a href="#ref-rouder_introduction_2005" role="doc-biblioref">Rouder and Lu 2005</a>)</span>. This latter point means that we can easily fit the models for multiple participants (and items!) simultaneously, while at the same time pooling information across participants (and items). We will return to this point below.</p>
<p>Because we wrote the SDT model as a GLM, we have a variety of software options for estimating the model. For this simple model, you could just use base R’s <code>glm()</code>. Here, we use the Bayesian regression modeling R package brms <span class="citation" data-cites="burkner_brms:_2017 stan_development_team_rstan:_2016">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>; <a href="#ref-stan_development_team_rstan:_2016" role="doc-biblioref">Stan Development Team 2016a</a>)</span>, because its model formula syntax extends seamlessly to more complicated models that we will discuss later. We can estimate the GLM with brms’s <code>brm()</code> function, by providing as arguments a model formula in brms syntax (identical to base R model syntax for simple models), an outcome distribution with a link function, and a data frame.</p>
<p>brms’s model syntax uses variable names from the data. We regress the binary <code>sayold</code> responses on the binary <code>isold</code> predictor with the following formula: <code>sayold ~ isold</code>. The distribution of the outcomes is specified with <code>family</code> argument. To specify the bernoulli distribution with a probit link function, we use <code>family = bernoulli(link="probit")</code>. We will only model the first participant’s data (number 53), and therefore specify the data with <code>data = filter(confcontr, subno==53)</code>.</p>
<p>The <code>brm()</code> function also allows specifying prior distributions on the parameters, but for this introductory discussion we omit discussion of priors. In addition, to run multiple MCMC chains <span class="citation" data-cites="kruschke_doing_2014 ravenzwaaij_simple_2016">(<a href="#ref-kruschke_doing_2014" role="doc-biblioref">Kruschke 2014</a>; <a href="#ref-ravenzwaaij_simple_2016" role="doc-biblioref">van Ravenzwaaij, Cassey, and Brown 2016</a>)</span> in parallel, we set the <code>cores</code> argument to 4 (this makes the model estimation faster). Finally, we also specify <code>file</code>, to save the model to a file so that we don’t have to re-estimate the model whenever we restart R.</p>
<p>Putting these pieces together, we estimate the SDT model as a probit GLM, using data stored in <code>confcontr</code>, for subject 53 only, with the following function:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>evsdt_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>sayold</span> <span class='op'>~</span> <span class='va'>isold</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>bernoulli</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"probit"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='va'>confcontr</span>, <span class='va'>subno</span> <span class='op'>==</span> <span class='fl'>53</span><span class='op'>)</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel1-1"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The estimated model is saved in <code>evsdt_1</code>, whose <code>summary()</code> method returns a numerical summary of the estimated parameters along with some information and diagnostics about the model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = probit 
Formula: sayold ~ isold 
   Data: filter(confcontr, subno == 53) (Number of observations: 100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept    -0.31      0.18    -0.68     0.04 1.00     3487     2580
isold         0.39      0.25    -0.09     0.88 1.00     3634     2900

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>The regression parameters (<code>Intercept</code> (recall, <span class="math inline">\(c = -\beta_0\)</span>) and <code>isold</code> (<span class="math inline">\(d&#39; = \beta_1\)</span>)) are described in the “Population-Level Effects” table in the above output. <code>Estimate</code> reports the posterior means, which are comparable to maximum likelihood point estimates, and <code>Est.Error</code> reports the posterior standard deviations, which are comparable to standard errors. The next two columns report the parameter’s 95% Credible Intervals (CIs). The estimated parameters’ means match the point estimates we calculated by hand (see table above.)</p>
<p>In fact, the posterior modes will exactly correspond to the maximum likelihood estimates, if we use uniform priors. The posterior density of <em>d’</em> and <em>c</em>, for participant 53, is illustrated in Figure <a href="#fig:densityplot">2</a>: The maximum likelihood estimate is spot on the highest peak of the posterior density.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:densityplot"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot-1.png" alt="The (approximate) joint posterior density of subject 53's SDT parameters. Lighter yellow colors indicate higher posterior density. The red dot indicates the 'manually' calculated MLE point estimate of d'." width="624" data-distill-preview=1 />
<p class="caption">
Figure 2: The (approximate) joint posterior density of subject 53’s SDT parameters. Lighter yellow colors indicate higher posterior density. The red dot indicates the ‘manually’ calculated MLE point estimate of d’.
</p>
</div>
</div>
<p>Figure <a href="#fig:densityplot">2</a> raises some interesting questions: What happens if we ignore the uncertainty in the estimated parameters (the colorful cloud of decreasing plausibility around the peak)? The answer is that not much happens for inference about averages by ignoring the subject-specific parameters’ uncertainty, <em>if the design is balanced across participants.</em> But what will happen if we use the point estimates as predictors in some other regression, while ignoring their uncertainty? What are the implications of having very uncertain estimates? Should we trust the mode?</p>
<p>In any case, I hope the above has illustrated that the equal variance Gaussian SDT parameters are easy to obtain within the GLM framework. Next, we describe how to estimate the SDT model using brms’ nonlinear modeling syntax.</p>
<h3 id="estimate-evsdt-with-a-nonlinear-model">Estimate EVSDT with a nonlinear model</h3>
<p>Here, we write the EVSDT model in a similar way as the GLM above, but simply flip the criterion and <em>d’</em>. To do that we need to use brms’ nonlinear modelling syntax. This parameterization will give <em>c</em> directly, without the need to flip the estimated parameter value. Although conceptually similar to above, and not necessarily useful by itself, it might be useful to fit this small variation of the above GLM to get familiar with brms’ nonlinear modeling syntax. We write the model as follows <span class="citation" data-cites="decarlo_signal_1998">(<a href="#ref-decarlo_signal_1998" role="doc-biblioref">DeCarlo 1998</a>)</span>:</p>
<p><span class="math display">\[p_i = \Phi(d&#39;\mbox{isold}_i - c)\]</span></p>
<p>This model gives us direct estimates of <em>c</em> and <em>d’</em>. Writing and estimating nonlinear models can be considerably more involved than fitting GLMs. Accordingly, the code below is a bit more complicated. The key point here is, however, that using brms, we can estimate models that may be nonlinear without deviating too far from the basic formula syntax.</p>
<p>First, we’ll specify the model using the <code>bf()</code> function:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>m2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsformula.html'>bf</a></span><span class='op'>(</span>
  <span class='va'>sayold</span> <span class='op'>~</span> <span class='fu'>Phi</span><span class='op'>(</span><span class='va'>dprime</span> <span class='op'>*</span> <span class='va'>isold</span> <span class='op'>-</span> <span class='va'>c</span><span class='op'>)</span>,
  <span class='va'>dprime</span> <span class='op'>~</span> <span class='fl'>1</span>, <span class='va'>c</span> <span class='op'>~</span> <span class='fl'>1</span>,
  nl <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Let’s walk through this code line by line. On the first line, we specify the model of <code>sayold</code> responses. Recall that we are modeling the responses as Bernoulli distributed (this will be specified as an argument to the estimation function, below). Therefore, the right-hand side of the first line (after ~) is a model of the probability parameter (<span class="math inline">\(p_i\)</span>) of the Bernoulli distribution.</p>
<p>The two unknown parameters in the model, <em>d’</em> and <em>c</em>, are estimated from data, as indicated by the second line (i.e. <code>dprime ~ 1</code>). The third line is required to tell brms that the model is nonlinear. To further understand how to write models with brms’ nonlinear modeling syntax, see (<code>vignette("brms_nonlinear", package = "brms")</code>) (or <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_nonlinear.html">here</a>).</p>
<p>Because the parameters of nonlinear models can be more difficult to estimate, brms requires the user to set priors when <code>nl = TRUE</code>. We set somewhat arbitrary priors on <code>dprime</code> and <code>c</code> (the scale parameter is standard deviation, not variance):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>Priors</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>.5</span>, <span class='fl'>3</span><span class='op'>)</span>, nlpar <span class='op'>=</span> <span class='st'>"dprime"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1.5</span><span class='op'>)</span>, nlpar <span class='op'>=</span> <span class='st'>"c"</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>After specifying the model and priors, fitting the model is done again using <code>brm()</code> with only a few adjustments: because we specified the link function inside <code>bf()</code> (the <code>Phi()</code> function), we should explicitly set <code>link="identity"</code> in the <code>family</code> argument. Because nonlinear models are trickier to estimate, we also adjust the underlying Stan sampler’s <code>adapt_delta</code> parameter (this will make the MCMC a little slower but will return less noisy results).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>evsdt_2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>m2</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>bernoulli</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"identity"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='va'>confcontr</span>, <span class='va'>subno</span> <span class='op'>==</span> <span class='fl'>53</span><span class='op'>)</span>,
  prior <span class='op'>=</span> <span class='va'>Priors</span>,
  control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>adapt_delta <span class='op'>=</span> <span class='fl'>.99</span><span class='op'>)</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel1-2"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Notice that we now entered <code>m2</code> as the first argument, whereas with the first model, we simply wrote the formula inside the <code>brm()</code> function. These two ways are equivalent, but because this model is more complicated, I saved it into a variable as a separate line of code.</p>
<p>We can then compare the two models’ estimated parameters. Recall that the latter model directly reports the standardized false alarm rate (<em>c</em>).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = probit 
Formula: sayold ~ isold 
   Data: filter(confcontr, subno == 53) (Number of observations: 100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept    -0.31      0.18    -0.68     0.04 1.00     3487     2580
isold         0.39      0.25    -0.09     0.88 1.00     3634     2900

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = identity 
Formula: sayold ~ Phi(dprime * isold - c) 
         dprime ~ 1
         c ~ 1
   Data: filter(confcontr, subno == 53) (Number of observations: 100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
dprime_Intercept     0.39      0.25    -0.10     0.88 1.00     1202     1551
c_Intercept          0.31      0.18    -0.04     0.65 1.00     1125     1595

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>The results are very similar, but note that priors were included only in the nonlinear syntax model. The only real difference is that the MCMC algorithm explored <code>evsdt_2</code>’s posterior less efficiently, as shown by the smaller effective sample sizes (<code>..._ESS</code>) for both parameters. This means that the random draws from the posterior distribution, for <code>evsdt_2</code>, have greater autocorrelation, and therefore we should possibly draw more samples for more accurate inference. The posterior distributions obtained with the 2 methods are shown in Figure <a href="#fig:densityplot2">3</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:densityplot2"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/densityplot2-1.png" alt="Top row: The (approximate) joint posterior density of subject 53's SDT parameters, estimated with the GL model and the nonlinear model. Lighter yellow colors indicate higher posterior density. The red dot indicates the sample mean d' that was calculated 'manually'. Bottom row: The marginal posterior densities of c and dprime from GLM (red) and nonlinear (blue) models." width="624" />
<p class="caption">
Figure 3: Top row: The (approximate) joint posterior density of subject 53’s SDT parameters, estimated with the GL model and the nonlinear model. Lighter yellow colors indicate higher posterior density. The red dot indicates the sample mean d’ that was calculated ‘manually.’ Bottom row: The marginal posterior densities of c and dprime from GLM (red) and nonlinear (blue) models.
</p>
</div>
</div>
<p>There is little benefit in using the second, “nonlinear” parameterization of EVSDT in this case. However, it is useful to study this simpler case to make it easier to understand how to fit more complicated nonlinear models with brms.</p>
<h3 id="interim-discussion">Interim discussion</h3>
<h4 id="fitting-one-subjects-evsdt-model-with-different-methods">Fitting one subject’s EVSDT model with different methods</h4>
<p>We have now estimated the equal variance Gaussian SDT model’s parameters for one subject’s data using three methods: Calculating point estimates manually, with a probit GLM, and with a probit model using brms’ nonlinear modeling syntax. The main difference between these methods, so far, is that the modeling methods provide estimates of uncertainty in the parameters, whereas the manual calculation does not. This point leads us directly to hierarchical models <span class="citation" data-cites="rouder_introduction_2005 rouder_signal_2007">(<a href="#ref-rouder_introduction_2005" role="doc-biblioref">Rouder and Lu 2005</a>; <a href="#ref-rouder_signal_2007" role="doc-biblioref">Rouder et al. 2007</a>)</span>, which we discuss next.</p>
<p>However, there are other, perhaps more subtle, benefits of using a regression model framework for estimating SDT models. There is something to be said, for example, about the fact that the models take the raw data as input. ‘Manual’ calculation involves, well, manual computation of values, which may be more error prone than using raw data. This is especially clear if the modeling methods are straightforward to apply: I hope to have illustrated that with R and brms <span class="citation" data-cites="burkner_brms:_2017">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>)</span>, Bayesian modeling methods are easy to apply and accessible to a wide audience.</p>
<p>Moving to a modeling framework will also allow us to include multiple sources of variation, such as heterogeneity across items and participants, through crossed “random” effects <span class="citation" data-cites="rouder_signal_2007">(<a href="#ref-rouder_signal_2007" role="doc-biblioref">Rouder et al. 2007</a>)</span>, and covariates that we think might affect the SDT parameters. By changing the link function, we can also easily use other distributions, such as logistic, to represent the signal and noise distributions <span class="citation" data-cites="decarlo_signal_1998 decarlo_statistical_2010">(<a href="#ref-decarlo_signal_1998" role="doc-biblioref">DeCarlo 1998</a>, <a href="#ref-decarlo_statistical_2010" role="doc-biblioref">2010</a>)</span>.</p>
<h4 id="prior-distribution">Prior distribution</h4>
<p>Finally, priors. Newcomers to the Bayesian modeling framework might object to the use of prior distributions, and think that they are unduly biasing the results. However, moderately informative priors usually have far less of an influence on inference than newcomers might assume. Above, we specified the GLM with practically no prior information; if you are reluctant to include existing knowledge into your model, feel free to leave it out. Things are, unfortunately, a little more complicated with the nonlinear modeling functions: The posterior geometry might be funky (technical term), in which case the priors could mainly serve to nudge the posterior samples to be drawn from sensible parameter values.</p>
<p>Further, priors can be especially useful in estimating SDT models: If participants’ hit or false alarm rates are 0 or 1–a fairly common scenario–mild prior information can be used in a principled manner to release the estimated quantities from the hostile captivity of the boundary values. Prior literature has discussed various corrections to 0 and 1 rates <span class="citation" data-cites="stanislaw_calculation_1999">(<a href="#ref-stanislaw_calculation_1999" role="doc-biblioref">Stanislaw and Todorov 1999</a>)</span>. However, Bayesian priors can take care of these edge cases in a more principled manner.</p>
<h2 id="evsdt-for-multiple-participants">EVSDT for multiple participants</h2>
<p>Above, we obtained parameter estimates of the EVSDT model for a single subject using three methods: Manual calculation of point estimates <span class="citation" data-cites="stanislaw_calculation_1999">(<a href="#ref-stanislaw_calculation_1999" role="doc-biblioref">Stanislaw and Todorov 1999</a>)</span>, estimating the model as a GLM (Generalized Linear Model; <span class="citation" data-cites="decarlo_signal_1998"><a href="#ref-decarlo_signal_1998" role="doc-biblioref">DeCarlo</a> (<a href="#ref-decarlo_signal_1998" role="doc-biblioref">1998</a>)</span>), and estimating the model as a GLM using brms’ nonlinear modeling syntax <span class="citation" data-cites="burkner_brms:_2017">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>)</span>.</p>
<p>However, researchers are usually not as interested in the specific subjects that happened to participate in their experiment, as they are in the population of potential subjects. Therefore, we are unsatisfied with parameters which describe only the subjects that happened to participate in our study: The final statistical model should have parameters that estimate features of the population of interest.</p>
<p>Broadly, there are two methods for obtaining these “population level” parameters. By far the most popular method is to summarise the manually calculated subject-specific point estimates of <em>d’</em> and <em>c</em> with their sample means and standard deviations. From these, we can calculate standard errors, t-tests, confidence intervals, etc. Another method–which I hope to motivate here–is to build a bigger model that estimates subject-specific and population-level parameters simultaneously. We call this latter method “hierarchical” or “multilevel” modeling <span class="citation" data-cites="gelman_data_2007 rouder_introduction_2005">(<a href="#ref-gelman_data_2007" role="doc-biblioref">Gelman and Hill 2007</a>; <a href="#ref-rouder_introduction_2005" role="doc-biblioref">Rouder and Lu 2005</a>)</span>. In this section, I show how to obtain population-level EVSDT parameters with these two methods, using the R programming language and the brms R package <span class="citation" data-cites="r_core_team_r:_2017 burkner_brms:_2017">(<a href="#ref-r_core_team_r:_2017" role="doc-biblioref">R Core Team 2017</a>; <a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>)</span>.</p>
<h3 id="population-level-evsdt-model">Population-level EVSDT Model</h3>
<p>We now use these data to estimate the population-level EVSDT parameters using two methods: Manual calculation and hierarchical modeling. For hierarchical modeling, I provide R &amp; brms code to estimate the model as a Generalized Linear Mixed Model (GLMM). I also show how to estimate the GLMM with brms’ nonlinear modeling syntax.</p>
<h4 id="estimation-by-summarizing-subjects-point-estimates">Estimation by summarizing subjects’ point estimates</h4>
<p>Above we calculated <em>d’</em> and <em>c</em> for every participant in the sample:</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:unnamed-chunk-8">Table 3: </span>Sample participants’ SDT parameters</caption>
<thead>
<tr class="header">
<th style="text-align: right;">subno</th>
<th style="text-align: right;">cr</th>
<th style="text-align: right;">fa</th>
<th style="text-align: right;">hit</th>
<th style="text-align: right;">miss</th>
<th style="text-align: right;">zhr</th>
<th style="text-align: right;">zfa</th>
<th style="text-align: right;">dprime</th>
<th style="text-align: right;">crit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">53</td>
<td style="text-align: right;">33</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">22</td>
<td style="text-align: right;">0.08</td>
<td style="text-align: right;">-0.31</td>
<td style="text-align: right;">0.39</td>
<td style="text-align: right;">0.31</td>
</tr>
<tr class="even">
<td style="text-align: right;">54</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">-0.63</td>
<td style="text-align: right;">0.87</td>
<td style="text-align: right;">0.63</td>
</tr>
<tr class="odd">
<td style="text-align: right;">55</td>
<td style="text-align: right;">36</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">31</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">0.41</td>
<td style="text-align: right;">-0.47</td>
<td style="text-align: right;">0.88</td>
<td style="text-align: right;">0.47</td>
</tr>
<tr class="even">
<td style="text-align: right;">56</td>
<td style="text-align: right;">43</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0.87</td>
<td style="text-align: right;">-0.88</td>
<td style="text-align: right;">1.76</td>
<td style="text-align: right;">0.88</td>
</tr>
<tr class="odd">
<td style="text-align: right;">57</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0.30</td>
<td style="text-align: right;">-0.41</td>
<td style="text-align: right;">0.71</td>
<td style="text-align: right;">0.41</td>
</tr>
<tr class="even">
<td style="text-align: right;">58</td>
<td style="text-align: right;">41</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">30</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0.35</td>
<td style="text-align: right;">-0.75</td>
<td style="text-align: right;">1.10</td>
<td style="text-align: right;">0.75</td>
</tr>
</tbody>
</table>
</div>
<p>We can therefore calculate sample means and standard errors for both parameters using these individual-specific values. Here’s one way to do it:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>sdt_sum</span> <span class='op'>&lt;-</span> <span class='fu'>select</span><span class='op'>(</span><span class='va'>sdt</span>, <span class='va'>subno</span>, <span class='va'>dprime</span>, <span class='va'>crit</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='co'># Select these variables only</span>
  <span class='fu'>gather</span><span class='op'>(</span><span class='va'>parameter</span>, <span class='va'>value</span>, <span class='op'>-</span><span class='va'>subno</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='co'># Convert data to long format</span>
  <span class='fu'>group_by</span><span class='op'>(</span><span class='va'>parameter</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='co'># Prepare to summarise on these grouping variables</span>
  <span class='co'># Calculate summary statistics for grouping variables</span>
  <span class='fu'>summarise</span><span class='op'>(</span>n <span class='op'>=</span> <span class='fu'>n</span><span class='op'>(</span><span class='op'>)</span>, mu <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>value</span><span class='op'>)</span>, sd <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/sd.html'>sd</a></span><span class='op'>(</span><span class='va'>value</span><span class='op'>)</span>, se <span class='op'>=</span> <span class='va'>sd</span> <span class='op'>/</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>n</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<caption><span id="tab:unnamed-chunk-9">Table 4: </span>Average EVSDT parameters</caption>
<thead>
<tr class="header">
<th style="text-align: left;">parameter</th>
<th style="text-align: right;">n</th>
<th style="text-align: right;">mu</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">se</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">crit</td>
<td style="text-align: right;">31</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">0.33</td>
<td style="text-align: right;">0.06</td>
</tr>
<tr class="even">
<td style="text-align: left;">dprime</td>
<td style="text-align: right;">31</td>
<td style="text-align: right;">1.09</td>
<td style="text-align: right;">0.50</td>
<td style="text-align: right;">0.09</td>
</tr>
</tbody>
</table>
</div>
<p>The sample means (<code>mu</code>) are estimates of the population means, and the sample standard deviations (<code>sd</code>) divided by <span class="math inline">\(\sqrt{N subjects}\)</span> are estimated standard deviations of the respective sampling distributions: the standard errors (<code>se</code>). Because the standard deviations of the sampling distributions are unknown and therefore estimated from the data, researchers almost always substitute the Gaussian sampling distribution with a Student’s <em>t</em>-distribution to obtain <em>p</em>-values and confidence intervals (i.e. we run <em>t</em>-tests, not <em>z</em>-tests.)</p>
<p>Note that this method involves calculating point estimates of unknown parameters (the subject-specifc parameters), and then summarizing these parameters with additional models. In other words, we first fit N models with P parameters each (N = number of subjects, P = 2 parameters), and then P more models to summarise the subject-specific models.</p>
<p>Next, we’ll use hierarchical regression<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> methods to obtain subject-specific and population-level parameters in one single step.</p>
<h4 id="estimation-with-a-hierarchical-model-glmm">Estimation with a hierarchical model (GLMM)</h4>
<p>We can estimate the EVSDT model’s parameters for every subject and the population average in one step using a Generalized Linear Mixed Model (GLMM). <span class="citation" data-cites="gelman_data_2007"><a href="#ref-gelman_data_2007" role="doc-biblioref">Gelman and Hill</a> (<a href="#ref-gelman_data_2007" role="doc-biblioref">2007</a>)</span> and <span class="citation" data-cites="mcelreath_statistical_2016"><a href="#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath</a> (<a href="#ref-mcelreath_statistical_2016" role="doc-biblioref">2016</a>)</span> are good general introductions to hierarchical models. <span class="citation" data-cites="rouder_introduction_2005"><a href="#ref-rouder_introduction_2005" role="doc-biblioref">Rouder and Lu</a> (<a href="#ref-rouder_introduction_2005" role="doc-biblioref">2005</a>)</span> and <span class="citation" data-cites="rouder_signal_2007"><a href="#ref-rouder_signal_2007" role="doc-biblioref">Rouder et al.</a> (<a href="#ref-rouder_signal_2007" role="doc-biblioref">2007</a>)</span> discuss hierarchical modeling in the context of signal detection theory.</p>
<p>This model is very much like the GLM discussed in Part 1, but now the subject-specific <em>d’</em>s and <em>c</em>s are modeled as draws from a multivariate normal distribution, whose (“hyper”)parameters describe the population-level parameters. We subscript subjects’ parameters with <em>j</em>, rows in data with <em>i</em>, and write the model as:</p>
<p><span class="math display">\[y_{ij} \sim Bernoulli(p_{ij})\]</span> <span class="math display">\[\Phi(p_{ij}) = \beta_{0j} + \beta_{1j}\mbox{isold}_{ij}\]</span></p>
<p>The outcomes <span class="math inline">\(y_{ij}\)</span> are 0 if participant <em>j</em> responded “new!” on trial <em>i</em>, 1 if they responded “old!” The probability of the “old!” response for row <em>i</em> for subject <em>j</em> is <span class="math inline">\(p_{ij}\)</span>. We then write a linear model on the probits (<em>z</em>-scores; <span class="math inline">\(\Phi\)</span>, “Phi”) of <em>p</em>s. The subject-specific intercepts (recall, <span class="math inline">\(\beta_0\)</span> = <em>-zFAR</em>) and slopes (<span class="math inline">\(\beta_1\)</span> = <em>d’</em>) are described by multivariate normal with means and a covariance matrix for the parameters.</p>
<p><span class="math display">\[
\left[\begin{array}{c}
\beta_{0j} \\ \beta_{1j}
\end{array}\right] 
\sim MVN(
\left[\begin{array}{c}
\mu_{0} \\ \mu_{1}
\end{array}\right],
\Sigma
)
\]</span></p>
<p>The means <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\mu_1\)</span>, i.e. the population-level parameters, can be interpreted as parameters “for the average person” <span class="citation" data-cites="bolger_intensive_2013">(<a href="#ref-bolger_intensive_2013" role="doc-biblioref">Bolger and Laurenceau 2013</a>)</span>. The covariance matrix <span class="math inline">\(\Sigma\)</span> contains the subject-specific parameters’ (co)variances, but I find it easier to discuss standard deviations (I call them <span class="math inline">\(\tau\)</span>, “tau”) and correlations. The standard deviations describe the between-person heterogeneities in the population. The correlation term, in turn, describes the covariance of the <em>d’</em>s and <em>c</em>s: Are people with higher <em>d’</em>s more likely to have higher <em>c</em>s?</p>
<p>This model is therefore more informative than running multiple separate GLMs, because it models the covariances as well, answering important questions about heterogeneity in effects.</p>
<p>The brms syntax for this model is very similar to the one-subject model. We have five population-level parameters to estimate. The intercept and slope describe the means: In R and brms modeling syntax, an intercept is indicated with <code>1</code> (and can be omitted because it is automatically included, here I include it for clarity), and slope of a variable by including that variable’s name in the data. To include the two regression coefficients, we write <code>sayold ~ 1 + isold</code>.</p>
<p>However, we also have three (co)variance parameters to estimate. To include subject-specific parameters (recall, subjects are indexed by <code>subno</code> variable in data <code>d</code>), and therefore the (co)variance parameters, we expand the formula to <code>sayold ~ 1 + isold + (1 + isold | subno)</code>. The part in the parentheses describes <code>subno</code> specific intercepts (<code>1</code>) and slopes of <code>isold</code>. Otherwise, the call to <code>brm()</code> is the same as with the GLM in Part 1:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>evsdt_glmm</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>sayold</span> <span class='op'>~</span> <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>isold</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>+</span> <span class='va'>isold</span> <span class='op'>|</span> <span class='va'>subno</span><span class='op'>)</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>bernoulli</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"probit"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='va'>confcontr</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel2-1"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Let’s take a look at the GLMM’s estimated parameters. First, direct your eyes to the “Population-Level Effects” table in the below output. These two parameters are the mean -criterion (<code>Intercept</code>, <span class="math inline">\(\mu_0\)</span>) and <em>d’</em> (<code>isold</code>, <span class="math inline">\(\mu_1\)</span>). Recall that we are looking at numerical summaries of (random samples from) the parameters’ posterior distributions: <code>Estimate</code> is the posterior mean.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_glmm</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = probit 
Formula: sayold ~ 1 + isold + (1 + isold | subno) 
   Data: confcontr (Number of observations: 3100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Group-Level Effects: 
~subno (Number of levels: 31) 
                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)            0.26      0.06     0.16     0.38 1.00     1379     2098
sd(isold)                0.38      0.08     0.24     0.56 1.00     1058     2014
cor(Intercept,isold)    -0.56      0.19    -0.84    -0.12 1.00     1041     1869

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept    -0.66      0.06    -0.78    -0.55 1.00     1632     2208
isold         1.06      0.09     0.89     1.23 1.00     1565     1889

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>We can then compare the Population-level mean parameters of this model to the sample summary statistics we calculated above. The posterior means map nicely to the calculated means, and the posterior standard deviations match the calculated standard errors.</p>
<p>These mean effects are visualized as a colored density in the left panel of Figure <a href="#fig:evsdt-glmm-viz1">4</a>. However, the GLMM also returns estimates of the parameters’ (co)variation in the population. Notice that we also calculated the sample standard deviations, which also provide this information, but we have no estimates of uncertainty in those point estimates. The GLMM, on the other hand, provides full posterior distributions for these parameters.</p>
<p>The heterogeneity parameters are reported in the “Group-Level Effects”<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> table, above. We find that the criteria are positively correlated with <em>d’</em>s (recall that Intercept = -<em>c</em>). The two standard deviations are visualized in the right panel of Figure <a href="#fig:evsdt-glmm-viz1">4</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:evsdt-glmm-viz1"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt-glmm-viz1-1.png" alt="Left panel: The (approximate) joint posterior density of the average d' and criterion. Lighter values indicate higher posterior probability. Right panel: The (approximate) joint posterior density of the standard deviations of d's and criteria in the population. In both panels, the red dot indicates the 'manually' calculated sample statistics." width="624" />
<p class="caption">
Figure 4: Left panel: The (approximate) joint posterior density of the average d’ and criterion. Lighter values indicate higher posterior probability. Right panel: The (approximate) joint posterior density of the standard deviations of d’s and criteria in the population. In both panels, the red dot indicates the ‘manually’ calculated sample statistics.
</p>
</div>
</div>
<p>It is evident in Figure <a href="#fig:evsdt-glmm-viz1">4</a> that the sample means approximately match the posterior mode, but less so for the sample standard deviations, which are far from the peak of the standard deviations’ posterior distribution. By ignoring the uncertainty in the subject-specific parameters, the ‘manual calculation’ method has over-estimated the heterogeneity of <em>d’</em>s and <em>c</em>s in the population, in comparison to the GLMM which takes the subject-specific parameters’ uncertainty into account.</p>
<p>This idea has further implications, revealed by investigating the two methods’ estimates of the subject-specific parameters. Recall that the manual calculation method involved estimating (the point estimates of) a separate model for each participant. A hierarchical model considers all participants’ data simultaneously, and the estimates are allowed to inform each other via the shared prior distribution (right hand side of the equation repeated from above):</p>
<p><span class="math display">\[
\left[\begin{array}{c}
\beta_{0j} \\ \beta_{1j}
\end{array}\right] 
\sim N(
\left[\begin{array}{c}
\mu_{0} \\ \mu_{1}
\end{array}\right],
\Sigma
)
\]</span></p>
<p>This “partial pooling” of information <span class="citation" data-cites="gelman_data_2007">(<a href="#ref-gelman_data_2007" role="doc-biblioref">Gelman and Hill 2007</a>)</span> is evident when we plot the GLMM’s subject-specific parameters in the same scatterplot with the N models method (calculating point estimates separately for everybody; Figure <a href="#fig:evsdt-glmm-viz2">5</a>).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:evsdt-glmm-viz2"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/evsdt-glmm-viz2-1.png" alt="Subject-specific d's and criteria as given by the independent models (filled circles), and as estimated by the hierarchical model (empty circles). The hierarchical model shrinks the estimated parameters toward the overall mean parameters (red dot). This shrinkage is greater for more extreme parameter values: Each subject-specific parameter is a compromise between that subject's data, and other subjects in the sample. As the data points per subject, or the heterogeneity between subjects, increases, this shrinkage will decrease. The hierarchical model essentially says 'People are different, but not *that* different'." width="624" />
<p class="caption">
Figure 5: Subject-specific d’s and criteria as given by the independent models (filled circles), and as estimated by the hierarchical model (empty circles). The hierarchical model shrinks the estimated parameters toward the overall mean parameters (red dot). This shrinkage is greater for more extreme parameter values: Each subject-specific parameter is a compromise between that subject’s data, and other subjects in the sample. As the data points per subject, or the heterogeneity between subjects, increases, this shrinkage will decrease. The hierarchical model essentially says ‘People are different, but not <em>that</em> different.’
</p>
</div>
</div>
<p>We see that estimating the EVSDT model for many individuals simultaneously with a hierarchical model is both easy to fit and informative. Specifically, it is now easy to include predictors on the parameters, and answer questions about possible influences on <em>d’</em> and <em>c</em>.</p>
<h4 id="including-predictors">Including predictors</h4>
<p>Do the EVSDT parameters differ between groups of people? How about between conditions, within people? To answer these questions, we would repeat the manual calculation of parameters as many times as needed, and then draw inference by “submitting” the subject-specific parameters to e.g. an ANOVA model. The GLMM approach affords a more straightforward solution to including predictors: We simply add parameters to the regression model.</p>
<p>For example, if there were two groups of participants, indexed by variable <code>group</code> in data, we could extend the brms GLMM syntax to (the <code>...</code> is a placeholder for other arguments used above, I also dropped the <code>1</code> for clarity because they are implicitly included):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>sayold</span> <span class='op'>~</span> <span class='va'>isold</span> <span class='op'>*</span> <span class='va'>group</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>isold</span> <span class='op'>|</span> <span class='va'>subno</span><span class='op'>)</span>, <span class='va'>...</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>This model would have two additional parameters: <code>group</code> would describe the difference in <em>c</em> between groups, and the interaction term <code>isold:group</code> would describe the difference in <em>d’</em> between groups. If, on the other hand, we were interested in the effects of <code>condition</code>, a within-subject manipulation, we would write:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>sayold</span> <span class='op'>~</span> <span class='va'>isold</span> <span class='op'>*</span> <span class='va'>condition</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>isold</span> <span class='op'>*</span> <span class='va'>condition</span> <span class='op'>|</span> <span class='va'>subno</span><span class='op'>)</span>, <span class='va'>...</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>With small changes, this syntax extends to “mixed” between- and within-subject designs.</p>
<h4 id="estimation-with-a-glmm-nonlinear-syntax">Estimation with a GLMM (nonlinear syntax)</h4>
<p>Here, I briefly describe fitting the above GLMM with brms’ nonlinear model syntax. The basic model is a straightforward reformulation of the single-subject case in Part 1 and the GLMM described above:</p>
<p><span class="math display">\[p_{ij} = \Phi(d&#39;_j\mbox{isold}_{ij} - c_{j})\]</span></p>
<p>The varying d-primes and criteria are modeled as multivariate normal, as with the GLMM. It turns out that this rather complex model is surprisingly easy to fit with brms. The formula is very similar to the single-subject nonlinear model but we tell <code>bf()</code> that the dprimes and criteria should have subject-specific parameters, as well as population-level parameters.</p>
<p>Above, with the GLMM, subject-specific effects were given by <code>(1 + isold | subno)</code>. With the nonlinear modeling syntax, we specify varying effects across multiple parameters using <code>|s|</code> instead of <code>|</code> to tell brms that these parameters should be within one covariance matrix. This syntax gives us the “correlated random effects signal detection model” discussed in <span class="citation" data-cites="rouder_signal_2007"><a href="#ref-rouder_signal_2007" role="doc-biblioref">Rouder et al.</a> (<a href="#ref-rouder_signal_2007" role="doc-biblioref">2007</a>)</span>. Apart from the syntax, the model is the same as the GLMM above, but the sign of the intercept is flipped.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>glmm2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsformula.html'>bf</a></span><span class='op'>(</span><span class='va'>sayold</span> <span class='op'>~</span> <span class='fu'>Phi</span><span class='op'>(</span><span class='va'>dprime</span> <span class='op'>*</span> <span class='va'>isold</span> <span class='op'>-</span> <span class='va'>c</span><span class='op'>)</span>,
  <span class='va'>dprime</span> <span class='op'>~</span> <span class='fl'>1</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>|</span> <span class='va'>s</span> <span class='op'>|</span> <span class='va'>subno</span><span class='op'>)</span>,
  <span class='va'>c</span> <span class='op'>~</span> <span class='fl'>1</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>|</span> <span class='va'>s</span> <span class='op'>|</span> <span class='va'>subno</span><span class='op'>)</span>,
  nl <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>This time, we’ll set priors on the mean parameters and on the (co)variance parameters. Of note is the <code>lkj(4)</code> parameter which slightly regularizes the <em>d’</em>-<em>criterion</em> correlation toward zero <span class="citation" data-cites="mcelreath_statistical_2016 stan_development_team_stan:_2016">(<a href="#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath 2016</a>; <a href="#ref-stan_development_team_stan:_2016" role="doc-biblioref">Stan Development Team 2016b</a>)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>Priors</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>3</span><span class='op'>)</span>, nlpar <span class='op'>=</span> <span class='st'>"dprime"</span>, lb <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>3</span><span class='op'>)</span>, nlpar <span class='op'>=</span> <span class='st'>"c"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>10</span>, <span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"sd"</span>, nlpar <span class='op'>=</span> <span class='st'>"dprime"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>10</span>, <span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"sd"</span>, nlpar <span class='op'>=</span> <span class='st'>"c"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>lkj</span><span class='op'>(</span><span class='fl'>4</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"cor"</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We fit the model as before, but adjust the <code>control</code> argument, and set <code>inits</code> to zero to improve sampling efficiency (thanks to <a href="https://twitter.com/tsawallis">Tom Wallis</a> for this tip):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>evsdt_glmm2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>glmm2</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>bernoulli</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"identity"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='va'>confcontr</span>,
  prior <span class='op'>=</span> <span class='va'>Priors</span>,
  control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>adapt_delta <span class='op'>=</span> <span class='fl'>.99</span><span class='op'>)</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>, inits <span class='op'>=</span> <span class='fl'>0</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel2-2"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Although this model samples less efficiently than the first GLMM formulation, we (unsurprisingly) observe similar results.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_glmm</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = probit 
Formula: sayold ~ 1 + isold + (1 + isold | subno) 
   Data: confcontr (Number of observations: 3100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Group-Level Effects: 
~subno (Number of levels: 31) 
                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)            0.26      0.06     0.16     0.38 1.00     1379     2098
sd(isold)                0.38      0.08     0.24     0.56 1.00     1058     2014
cor(Intercept,isold)    -0.56      0.19    -0.84    -0.12 1.00     1041     1869

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept    -0.66      0.06    -0.78    -0.55 1.00     1632     2208
isold         1.06      0.09     0.89     1.23 1.00     1565     1889

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>evsdt_glmm2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: bernoulli 
  Links: mu = identity 
Formula: sayold ~ Phi(dprime * isold - c) 
         dprime ~ 1 + (1 | s | subno)
         c ~ 1 + (1 | s | subno)
   Data: confcontr (Number of observations: 3100) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Group-Level Effects: 
~subno (Number of levels: 31) 
                                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(dprime_Intercept)                  0.36      0.08     0.23     0.52 1.00     1687     2077
sd(c_Intercept)                       0.24      0.05     0.15     0.35 1.00     1199     2077
cor(dprime_Intercept,c_Intercept)     0.43      0.20    -0.01     0.75 1.00     1111     2041

Population-Level Effects: 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
dprime_Intercept     1.06      0.08     0.90     1.22 1.00     1514     2148
c_Intercept          0.66      0.06     0.55     0.77 1.00     1726     2400

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>For technical reasons, each parameter in <code>evsdt_glmm2</code> has a <code>_Intercept</code> suffix, but the results are the same across the two ways of writing this model.</p>
<h3 id="interim-discussion-1">Interim discussion</h3>
<p>Hierarchical modeling techniques have several advantages over traditional methods, such as (M)ANOVA, for modeling data with within-subject manipulations and repeated measures. For example, many models that previously required using parameters from subject-specific models as inputs to another model can be modeled within a single hierarchical model. Hierarchical models naturally account for unbalanced data, and allow incorporating continuous predictors and discrete outcomes. In the specific context of SDT, we observed that hierarchical models also estimate important parameters that describe possible between-person variability in parameters in the population of interest.</p>
<p>From casual observation, it appears that hierarchical models are becoming more widely used. Many applied papers now analyze data using multilevel models, instead of rm-ANOVA, suggesting that there is demand for these models within applied research contexts. Conceptualizing more complex, possibly nonlinear models as hierarchical models should then afford a more unified framework for data analysis. Furthermore, by including parameters for between-person variability, these models allow researchers to quantify the extent to which their effects of interest vary and, possibly, whether these effects hold for everybody in the population.</p>
<h2 id="unequal-variance-gaussian-sdt-model">Unequal variance Gaussian SDT model</h2>
<p>Next, I extend the discussion to rating tasks to show how unequal variance Gaussian SDT (UVSDT) models can be estimated with with Bayesian methods, using R and the brms package <span class="citation" data-cites="burkner_brms:_2017 r_core_team_r:_2017">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>; <a href="#ref-r_core_team_r:_2017" role="doc-biblioref">R Core Team 2017</a>)</span>. As above, we first focus on estimating the model for a single participant, and then discuss hierarchical models for multiple participants.</p>
<h3 id="example-data-rating-task">Example data: Rating task</h3>
<p>We begin with a brief discussion of the rating task, with example data from <span class="citation" data-cites="decarlo_using_2003"><a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo</a> (<a href="#ref-decarlo_using_2003" role="doc-biblioref">2003</a>)</span>. Above, we discussed signal detection experiments where the item was either old or new, and participants provided binary “old!” or “new!” responses. Here, we move to a slight modification of this task, where participants are allowed to express their certainty: On each trial, the presented item is still old or new, but participants now <em>rate their confidence</em> in whether the item was old or new. For example, and in the data below, participants can answer with numbers indicating their confidence that the item is old: 1 = Definitely new, …, 6 = Definitely old.</p>
<p>One interpretation of the resulting data is that participants set a number of criteria for the confidence ratings, such that greater evidence is required for 6-responses, than 4-responses, for example. That is, there will be different criteria for responding “definitely new,” “maybe new,” and so forth. However, the participant’s underlying discriminability should remain unaffected.</p>
<p>The example data is shown in a summarised form below (counts of responses for each confidence bin, for both old (<code>isold</code> = 1) and new trial types <span class="citation" data-cites="decarlo_using_2003">(<a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo 2003</a>)</span>):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>dsum</span> <span class='op'>&lt;-</span> <span class='fu'>tibble</span><span class='op'>(</span>
  isold <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>1</span>, <span class='fl'>1</span>, <span class='fl'>1</span>, <span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>,
  y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>6</span>, <span class='fl'>1</span><span class='op'>:</span><span class='fl'>6</span><span class='op'>)</span>,
  count <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>174</span>, <span class='fl'>172</span>, <span class='fl'>104</span>, <span class='fl'>92</span>, <span class='fl'>41</span>, <span class='fl'>8</span>, <span class='fl'>46</span>, <span class='fl'>57</span>, <span class='fl'>66</span>, <span class='fl'>101</span>, <span class='fl'>154</span>, <span class='fl'>173</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
<table>
<caption><span id="tab:unnamed-chunk-18">Table 5: </span>Example rating data from Decarlo (2003)</caption>
<thead>
<tr class="header">
<th style="text-align: right;">isold</th>
<th style="text-align: right;">y</th>
<th style="text-align: right;">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">174</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">172</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">104</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">92</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">41</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">46</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">57</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">66</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">101</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">154</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">173</td>
</tr>
</tbody>
</table>
</div>
<p>However, we don’t need to summarise data to counts (or cell means, or the like), but can instead work with raw responses, as provided by the experimental program. Working with such trial-level data is especially useful when we wish to include covariates. Here is the data in the raw trial-level format:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>d</span> <span class='op'>&lt;-</span> <span class='fu'>uncount</span><span class='op'>(</span><span class='va'>dsum</span>, weights <span class='op'>=</span> <span class='va'>count</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<caption><span id="tab:unnamed-chunk-19">Table 6: </span>Example rating data in raw format from Decarlo (2003)</caption>
<thead>
<tr class="header">
<th style="text-align: right;">isold</th>
<th style="text-align: right;">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
<p>We can now proceed to fit the SDT models to this person’s data, beginning with the EVSDT model.</p>
<h3 id="evsdt-one-subjects-rating-responses">EVSDT: one subject’s rating responses</h3>
<p>Recall that for the EVSDT model of binary responses, we modeled the probability <em>p</em> (of responding “old!” on trial <em>i</em>) as</p>
<p><span class="math display">\[p_i = \Phi(d&#39;\mbox{isold}_i - c)\]</span></p>
<p>This model gives the (z-scored) probability of responding “old” for new items (<em>c</em> = zFAR), and the increase (in z-scores) in “old” responses for old items (<em>d’</em>). For rating data, the model is similar but we now include multiple <em>c</em>s. These index the different criteria for responding with the different confidence ratings. The criteria are assumed to be ordered–people should be more lenient to say unsure old, vs. sure old, when the signal (memory strength) on that trial was weaker.</p>
<p>The EVSDT model for rating responses models the <em>cumulative probability</em> of responding with confidence rating <em>k</em> or less (<span class="math inline">\(p(y_i \leq k_i)\)</span>; <span class="citation" data-cites="decarlo_using_2003"><a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo</a> (<a href="#ref-decarlo_using_2003" role="doc-biblioref">2003</a>)</span>):</p>
<p><span class="math display">\[p(y_i \leq k_i) = \Phi(d&#39;\mbox{isold}_i - c_{ki})\]</span></p>
<p>This model is also known as an ordinal probit (<span class="math inline">\(\Phi\)</span>) model, and can be fit with widely available regression modeling software. <span class="citation" data-cites="decarlo_using_2003">(<a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo 2003</a>)</span> showed how to use the PLUM procedure in SPSS to fit it for a single participant. However, we can obtain Bayesian inference for this model by estimating the model with the brms package in R <span class="citation" data-cites="burkner_brms:_2017 stan_development_team_stan:_2016">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>; <a href="#ref-stan_development_team_stan:_2016" role="doc-biblioref">Stan Development Team 2016b</a>)</span>. Ignoring prior distributions for now, the brms syntax for estimating this model with the above data is:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>fit1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>y</span> <span class='op'>~</span> <span class='va'>isold</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>cumulative</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"probit"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='va'>d</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel3-1"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>This model estimates an intercept (criterion) for each response category, and the effect of <code>isold</code>, which is <em>d’</em>. The model’s posterior distribution is summarised below:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>fit1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: cumulative 
  Links: mu = probit; disc = identity 
Formula: y ~ isold 
   Data: d (Number of observations: 1188) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -0.44      0.05    -0.54    -0.35 1.00     4756     3101
Intercept[2]     0.23      0.05     0.14     0.32 1.00     5318     3355
Intercept[3]     0.67      0.05     0.57     0.77 1.00     4556     3486
Intercept[4]     1.20      0.06     1.10     1.31 1.00     3907     3191
Intercept[5]     1.88      0.07     1.75     2.01 1.00     3814     3312
isold            1.26      0.07     1.13     1.38 1.00     4059     3045

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00 1.00     4000     4000

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>The five intercepts are the five criteria in the model, and <code>isold</code> is <em>d’</em>. I also estimated this model using SPSS, so it might be helpful to compare the results from these two approaches:</p>
<pre><code>PLUM y WITH x
/CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)
/LINK=PROBIT
/PRINT=FIT KERNEL PARAMETER SUMMARY.

Parameter Estimates
|-----------------|--------|----------|-----------------------------------|
|                 |Estimate|Std. Error|95% Confidence Interval            |
|                 |        |          |-----------------------|-----------|
|                 |        |          |Lower Bound            |Upper Bound|
|---------|-------|--------|----------|-----------------------|-----------|
|Threshold|[y = 1]|-.442   |.051      |-.541                  |-.343      |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 2]|.230    |.049      |.134                   |.326       |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 3]|.669    |.051      |.569                   |.769       |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 4]|1.198   |.056      |1.088                  |1.308      |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 5]|1.876   |.066      |1.747                  |2.005      |
|---------|-------|--------|----------|-----------------------|-----------|
|Location |x      |1.253   |.065      |1.125                  |1.381      |
|-------------------------------------------------------------------------|
Link function: Probit.</code></pre>
<p>Unsurprisingly, the numerical results from brms (posterior means and standard deviations, credibility intervals) match the frequentist ones obtained from SPSS under these conditions.</p>
<p>We can now illustrate graphically how the estimated parameters map to the signal detection model. <em>d’</em> is the separation of the signal and noise distributions’ peaks: It indexes the subject’s ability to discriminate signal from noise trials. The five intercepts are the (z-scored) criteria for responding with the different confidence ratings. If we convert the z-scores to proportions (using R’s <code>pnorm()</code> for example), they measure the (cumulative) area under the noise distribution to the left of that z-score. The model is visualized in Figure <a href="#fig:fit1-plot">6</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:fit1-plot"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fit1-plot-1.png" alt="The equal variance Gaussian signal detection model, visualized from the parameters' posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d' is the distance between the peaks of the two distributions." width="624" />
<p class="caption">
Figure 6: The equal variance Gaussian signal detection model, visualized from the parameters’ posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d’ is the distance between the peaks of the two distributions.
</p>
</div>
</div>
<h3 id="uvsdt-one-subjects-rating-responses">UVSDT: one subject’s rating responses</h3>
<p>Notice that the above model assumed that the noise and signal distributions have the same variance. The unequal variances SDT (UVSDT) model allows the signal distribution to have a different variance than the noise distribution (whose standard deviation is still arbitrarily fixed at 1). It has been found that when the signal distribution’s standard deviation is allowed to vary, it is consistently greater than 1.</p>
<p>The UVSDT model adds one parameter, and we can write out the resulting model by including the signal distribution’s standard deviation as a scale parameter in the above equation <span class="citation" data-cites="decarlo_using_2003">(<a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo 2003</a>)</span>. However, because the standard deviation parameter must be greater than zero, it is convenient to model <span class="math inline">\(\mbox{log}(\sigma_{old}) = a\)</span> instead:</p>
<p><span class="math display">\[p(y_i \leq k_i) = \Phi(\frac{d&#39;\mbox{isold}_i - c_k}{\mbox{exp}(a\mbox{isold}_i)})\]</span></p>
<p>It turns out that this nonlinear model—also knows as a probit model with heteroscedastic error (e.g. <span class="citation" data-cites="decarlo_statistical_2010"><a href="#ref-decarlo_statistical_2010" role="doc-biblioref">DeCarlo</a> (<a href="#ref-decarlo_statistical_2010" role="doc-biblioref">2010</a>)</span>)—can be estimated with brms. Initially, I thought that we could write out a nonlinear brms formula for the ordinal probit model, but brms does not support nonlinear cumulative ordinal models. I then proceeded to modify the raw Stan code to estimate this model, but although that worked, it would be less practical for applied work because not everyone wants to go through the trouble of writing Stan code.</p>
<p>After some back and forth with the creator of brms—Paul Bürkner, who deserves a gold medal for his continuing hard work on this free and open-source software—I found out that brms by default includes a similar parameter in ordinal regression models. If you scroll back up and look at the summary of <code>fit1</code>, at the top you will see that the model’s formula is:</p>
<pre><code>Formula: y ~ isold 
disc = 1</code></pre>
<p>In other words, there is a “discrimination” parameter <code>disc</code>, which is set to 1 by default. Here’s how brms parameterizes the ordinal probit model:</p>
<p><span class="math display">\[p(y_i \leq k_i) = \Phi(disc * (c_{ki} - d&#39;\mbox{isold}_i))\]</span></p>
<p>Importantly, we can also include predictors on <code>disc</code>. In this case, we want to estimate <code>disc</code> when <code>isold</code> is 1, such that <code>disc</code> is 1 for new items, but estimated from data for old items. This parameter is by default modelled through a log link function, and including a 0/1 predictor (<code>isold</code>) will therefore work fine:</p>
<p><span class="math display">\[p(y_i \leq k_i) = \Phi(\mbox{exp}(disc\mbox{isold}_i) * (c_{ki} - d&#39;\mbox{isold}_i))\]</span></p>
<p>We can therefore estimate this model with only a small tweak to the EVSDT model’s code:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>uvsdt_m</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsformula.html'>bf</a></span><span class='op'>(</span><span class='va'>y</span> <span class='op'>~</span> <span class='va'>isold</span>, <span class='va'>disc</span> <span class='op'>~</span> <span class='fl'>0</span> <span class='op'>+</span> <span class='va'>isold</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>There are two brms formulas in the model. The first, <code>y ~ isold</code> is already familiar to us. In the second formula, we write <code>disc ~ 0 + isold</code> to prevent the parameter from being estimated for the noise distribution: Recall that we have set the standard deviation of the noise distribution to be one (achieved by <span class="math inline">\(exp(disc * \mbox{0}) = 1\)</span>). In R’s (and by extension, brms’) modeling syntax <code>0 + ...</code> means removing the intercept from the model. By including <code>isold</code> only, we achieve the 0/1 predictor as described above. We can then estimate the model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>fit2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>uvsdt_m</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>cumulative</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"probit"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='va'>d</span>,
  control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>adapt_delta <span class='op'>=</span> <span class='fl'>.99</span><span class='op'>)</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel3-2"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The model’s estimated parameters:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>fit2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: cumulative 
  Links: mu = probit; disc = log 
Formula: y ~ isold 
         disc ~ 0 + isold
   Data: d (Number of observations: 1188) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -0.54      0.05    -0.65    -0.43 1.00     3368     2690
Intercept[2]     0.20      0.05     0.10     0.30 1.00     5639     3303
Intercept[3]     0.71      0.05     0.61     0.81 1.00     4686     3152
Intercept[4]     1.37      0.07     1.24     1.51 1.00     2213     2560
Intercept[5]     2.31      0.11     2.09     2.54 1.00     1395     1995
isold            1.53      0.10     1.35     1.73 1.00     1746     2314
disc_isold      -0.36      0.06    -0.48    -0.23 1.00     1466     2548

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>Notice that we need to flip the sign of the <code>disc</code> parameter to get <span class="math inline">\(\mbox{log}(\sigma_{old})\)</span>. Exponentiation gives us the standard deviation of the signal distribution, and because we estimated the model in the Bayesian framework, our estimate of this parameter is a posterior distribution, plotted on the y-axis of Figure <a href="#fig:uvsdt-densityplot">7</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:uvsdt-densityplot"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/uvsdt-densityplot-1.png" alt="The (approximate) joint posterior density of two UVSDT parameters (d' and standard deviation of the signal distribution) fitted to one participant's data. Lighter yellow colors indicate higher posterior density. Red point shows the maximum likelihood estimates obtained from SPSS's ordinal regression module." width="624" />
<p class="caption">
Figure 7: The (approximate) joint posterior density of two UVSDT parameters (d’ and standard deviation of the signal distribution) fitted to one participant’s data. Lighter yellow colors indicate higher posterior density. Red point shows the maximum likelihood estimates obtained from SPSS’s ordinal regression module.
</p>
</div>
</div>
<p>We can also compare the results from brms’ to ones obtained from SPSS (SPSS procedure described in <span class="citation" data-cites="decarlo_using_2003">(<a href="#ref-decarlo_using_2003" role="doc-biblioref">Decarlo 2003</a>)</span>):</p>
<pre><code>PLUM y WITH x
/CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)
/LINK=PROBIT
/PRINT=FIT KERNEL PARAMETER SUMMARY
/SCALE=x .

Parameter Estimates
|-----------------|--------|----------|-----------------------------------|
|                 |Estimate|Std. Error|95% Confidence Interval            |
|                 |        |          |-----------------------|-----------|
|                 |        |          |Lower Bound            |Upper Bound|
|---------|-------|--------|----------|-----------------------|-----------|
|Threshold|[y = 1]|-.533   |.054      |-.638                  |-.428      |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 2]|.204    |.050      |.107                   |.301       |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 3]|.710    |.053      |.607                   |.813       |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 4]|1.366   |.067      |1.235                  |1.498      |
|         |-------|--------|----------|-----------------------|-----------|
|         |[y = 5]|2.294   |.113      |2.072                  |2.516      |
|---------|-------|--------|----------|-----------------------|-----------|
|Location |x      |1.519   |.096      |1.331                  |1.707      |
|---------|-------|--------|----------|-----------------------|-----------|
|Scale    |x      |.348    |.063      |.225                   |.472       |
|-------------------------------------------------------------------------|
Link function: Probit.</code></pre>
<p>Again, the maximum likelihood estimates (SPSS) match our Bayesian quantities numerically, because we used uninformative prior distributions. Plotting the model’s implied distributions illustrates that the signal distribution has greater variance than the noise distribution (Figure <a href="#fig:fit2-plot">8</a>).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:fit2-plot"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/fit2-plot-1.png" alt="The unequal variance Gaussian signal detection model, visualized from the parameters' posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d' is the scaled distance between the peaks of the two distributions." width="624" />
<p class="caption">
Figure 8: The unequal variance Gaussian signal detection model, visualized from the parameters’ posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d’ is the scaled distance between the peaks of the two distributions.
</p>
</div>
</div>
<p>Additional quantities of interest can be calculated from the parameters’ posterior distributions. One benefit of obtaining samples from the posterior is that if we complete these calculations row-wise, we automatically obtain (samples from) the posterior distributions of these additional quantities.</p>
<p>Here, we calculate one such quantity: The ratio of the noise to signal standard deviations (<span class="math inline">\(\mbox{exp}(-a)\)</span>; notice that our model returns <em>-a</em> as <em>disc_isold</em>), which is also the slope of the z-ROC curve. We’ll first obtain the posterior samples of <em>disc_isold</em>, then calculate the ratio, and summarize the samples from ratio’s posterior distribution with their 2.5%, 50%, and 97.5%iles:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/as.data.frame.html'>as.data.frame</a></span><span class='op'>(</span><span class='va'>fit2</span>, pars <span class='op'>=</span> <span class='st'>"b_disc_isold"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>transmute</span><span class='op'>(</span>ratio <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span><span class='op'>(</span><span class='va'>b_disc_isold</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>pull</span><span class='op'>(</span><span class='va'>ratio</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/stats/quantile.html'>quantile</a></span><span class='op'>(</span>probs <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>.025</span>, <span class='fl'>.5</span>, <span class='fl'>.975</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>     2.5%       50%     97.5% 
0.6160153 0.7004072 0.7926746 </code></pre>
</div>
<p>These summaries are the parameter’s 95% Credible interval and median, and as such can be used to summarize this quantity in a publication. We could also visualize the posterior draws as a histogram:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/as.data.frame.html'>as.data.frame</a></span><span class='op'>(</span><span class='va'>fit2</span>, pars <span class='op'>=</span> <span class='st'>"b_disc_isold"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>transmute</span><span class='op'>(</span>ratio <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span><span class='op'>(</span><span class='va'>b_disc_isold</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>ggplot</span><span class='op'>(</span><span class='fu'>aes</span><span class='op'>(</span><span class='va'>ratio</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>geom_histogram</span><span class='op'>(</span>col <span class='op'>=</span> <span class='st'>"black"</span>, fill <span class='op'>=</span> <span class='st'>"gray70"</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>scale_y_continuous</span><span class='op'>(</span>expand <span class='op'>=</span> <span class='fu'>expansion</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>.1</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>theme</span><span class='op'>(</span>aspect.ratio <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/unnamed-chunk-26-1.png" width="624" style="display: block; margin: auto;" /></p>
</div>
<h2 id="uvsdt-for-multiple-participants">UVSDT for multiple participants</h2>
<p>Above, we fit the UVSDT model for a single subject. However, we almost always want to discuss our inference about the population, not individual subjects. Further, if we wish to discuss individual subjects, we should place them in the context of other subjects. A multilevel (aka hierarchical, mixed) model accomplishes these goals by including population- and subject-level parameters.</p>
<h3 id="example-data-set">Example data set</h3>
<p>We’ll use a data set of 48 subjects’ confidence ratings on a 6 point scale: 1 = “sure new,” …, 6 = “sure old” <span class="citation" data-cites="koen_examining_2013">(<a href="#ref-koen_examining_2013" role="doc-biblioref">Koen et al. 2013</a>)</span>. This data set is included in the R package MPTinR <span class="citation" data-cites="singmann_mptinr:_2013">(<a href="#ref-singmann_mptinr:_2013" role="doc-biblioref">Singmann and Kellen 2013</a>)</span>.</p>
<p>In this experiment <span class="citation" data-cites="koen_examining_2013">(<a href="#ref-koen_examining_2013" role="doc-biblioref">Koen et al. 2013</a>)</span>, participants completed a study phase, and were then tested under full attention, or while doing a second task. Here, we focus on the rating data provided in the full attention condition. Below, I reproduce the aggregate rating counts for old and new items from the Table in the article’s appendix. (It is useful to ensure that we are indeed using the same data.)</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<caption><span id="tab:unnamed-chunk-27">Table 7: </span>Example data from Koen et al. (2013)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">isold</th>
<th style="text-align: right;">6</th>
<th style="text-align: right;">5</th>
<th style="text-align: right;">4</th>
<th style="text-align: right;">3</th>
<th style="text-align: right;">2</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">old</td>
<td style="text-align: right;">2604</td>
<td style="text-align: right;">634</td>
<td style="text-align: right;">384</td>
<td style="text-align: right;">389</td>
<td style="text-align: right;">422</td>
<td style="text-align: right;">309</td>
</tr>
<tr class="even">
<td style="text-align: left;">new</td>
<td style="text-align: right;">379</td>
<td style="text-align: right;">356</td>
<td style="text-align: right;">454</td>
<td style="text-align: right;">871</td>
<td style="text-align: right;">1335</td>
<td style="text-align: right;">1365</td>
</tr>
</tbody>
</table>
</div>
<p>For complete R code, including pre-processing the data, please refer to the source code of this blog post. I have omitted some of the less important code from the blog post for clarity.</p>
<h3 id="model-syntax">Model syntax</h3>
<p>Here’s the brms syntax we used for estimating the model for a single participant:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>uvsdt_m</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsformula.html'>bf</a></span><span class='op'>(</span><span class='va'>y</span> <span class='op'>~</span> <span class='va'>isold</span>, <span class='va'>disc</span> <span class='op'>~</span> <span class='fl'>0</span> <span class='op'>+</span> <span class='va'>isold</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>With the above syntax we specifed seven parameters: Five intercepts (aka ‘thresholds’ in the cumulative probit model) on <code>y</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>; the effect of <code>isold</code> on <code>y</code>; and the effect of <code>isold</code> on the discrimination parameter <code>disc</code><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. There are five intercepts (thresholds), because there are six response categories.</p>
<p>We extend the code to a hierarchical model by specifying that all these parameters vary across participants (variable <code>id</code> in the data).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>uvsdt_h</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsformula.html'>bf</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>isold</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>isold</span> <span class='op'>|</span> <span class='va'>s</span> <span class='op'>|</span> <span class='va'>id</span><span class='op'>)</span>,
  <span class='va'>disc</span> <span class='op'>~</span> <span class='fl'>0</span> <span class='op'>+</span> <span class='va'>isold</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>0</span> <span class='op'>+</span> <span class='va'>isold</span> <span class='op'>|</span> <span class='va'>s</span> <span class='op'>|</span> <span class='va'>id</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Recall from above that using <code>|s|</code> leads to estimating correlations among the varying effects. There will only be one standard deviation associated with the thresholds; that is, the model assumes that subjects vary around the mean threshold similarly for all thresholds.</p>
<h3 id="prior-distributions">Prior distributions</h3>
<p>I set a N(1, 3) prior on dprime, just because I know that in these tasks performance is usually pretty good. Perhaps this prior is also influenced by my reading of the paper! I also set a N(0, 1) prior on <em>a</em>: Usually this parameter is found to be around <span class="math inline">\(-\frac{1}{4}\)</span>, but I’m ignoring that information.</p>
<p>The <em>t(7, 0, .33)</em> priors on the between-subject standard deviations reflect my assumption that the subjects should be moderately similar to one another, but also allows larger deviations. (They are <em>t</em>-distributions with seven degrees of freedom, zero mean, and .33 standard deviation.)</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>Prior</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>3</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"b"</span>, coef <span class='op'>=</span> <span class='st'>"isold"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"b"</span>, coef <span class='op'>=</span> <span class='st'>"isold"</span>, dpar <span class='op'>=</span> <span class='st'>"disc"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>7</span>, <span class='fl'>0</span>, <span class='fl'>.33</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"sd"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>7</span>, <span class='fl'>0</span>, <span class='fl'>.33</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"sd"</span>, dpar <span class='op'>=</span> <span class='st'>"disc"</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>lkj</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>"cor"</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<h3 id="estimate-and-summarise-parameters">Estimate and summarise parameters</h3>
<p>We can then estimate the model as before. Be aware that this model takes quite a bit longer to estimate, so for this example I have set only 500 HMC iterations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>fit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span><span class='va'>uvsdt_h</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brmsfamily.html'>cumulative</a></span><span class='op'>(</span>link <span class='op'>=</span> <span class='st'>"probit"</span><span class='op'>)</span>,
  data <span class='op'>=</span> <span class='va'>d</span>,
  prior <span class='op'>=</span> <span class='va'>Prior</span>,
  control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>adapt_delta <span class='op'>=</span> <span class='fl'>.9</span><span class='op'>)</span>, inits <span class='op'>=</span> <span class='fl'>0</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>, iter <span class='op'>=</span> <span class='fl'>500</span>,
  file <span class='op'>=</span> <span class='st'>"sdtmodel4-1"</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We then display numerical summaries of the model’s parameters. Note that the effective sample sizes are modest, and Rhats indicate that we would benefit from drawing more samples from the posterior. For real applications, I recommend more than 500 iterations per chain.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>fit</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: cumulative 
  Links: mu = probit; disc = log 
Formula: y ~ isold + (isold | s | id) 
         disc ~ 0 + isold + (0 + isold | s | id)
   Data: d (Number of observations: 9502) 
Samples: 4 chains, each with iter = 500; warmup = 250; thin = 1;
         total post-warmup samples = 1000

Group-Level Effects: 
~id (Number of levels: 48) 
                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)                 0.34      0.04     0.28     0.43 1.01      252      364
sd(isold)                     0.78      0.10     0.60     1.01 1.01      153      202
sd(disc_isold)                0.46      0.05     0.37     0.56 1.03      183      269
cor(Intercept,isold)         -0.45      0.13    -0.65    -0.16 1.02      167      319
cor(Intercept,disc_isold)     0.34      0.13     0.08     0.57 1.02      198      454
cor(isold,disc_isold)        -0.76      0.07    -0.88    -0.59 1.02      217      381

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -0.59      0.05    -0.69    -0.49 1.03      169      364
Intercept[2]     0.21      0.05     0.11     0.30 1.03      167      405
Intercept[3]     0.71      0.05     0.61     0.80 1.03      158      356
Intercept[4]     1.05      0.05     0.95     1.14 1.03      160      323
Intercept[5]     1.50      0.05     1.39     1.60 1.03      164      411
isold            1.86      0.12     1.63     2.10 1.08       51      194
disc_isold      -0.38      0.07    -0.51    -0.25 1.04      101      304

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>Let’s first focus on the “Population-level Effects”: The effects for the “average person.” <code>isold</code> is <em>d’</em>, and is very close to the one reported in the paper (eyeballing Figure 3 in <span class="citation" data-cites="koen_examining_2013"><a href="#ref-koen_examining_2013" role="doc-biblioref">Koen et al.</a> (<a href="#ref-koen_examining_2013" role="doc-biblioref">2013</a>)</span>; this <em>d’</em> is not numerically reported in the paper). <code>disc_isold</code> is, because of the model’s parameterization, <span class="math inline">\(-\mbox{log}(\sigma_{signal}) = -a\)</span>. The paper discusses <span class="math inline">\(V_o = \sigma_{signal}\)</span>, and therefore we transform each posterior sample of our <em>-a</em> to obtain samples from <span class="math inline">\(V_o\)</span>’s posterior distribution.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>samples</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/posterior_samples.brmsfit.html'>posterior_samples</a></span><span class='op'>(</span><span class='va'>fit</span>, <span class='st'>"b_"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>mutate</span><span class='op'>(</span>Vo <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span><span class='op'>(</span><span class='op'>-</span><span class='va'>b_disc_isold</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We can then plot density curves <span class="citation" data-cites="gabry_bayesplot:_2017">(<a href="#ref-gabry_bayesplot:_2017" role="doc-biblioref">Gabry 2017</a>)</span> for each of the Population-level Effects in our model, including <span class="math inline">\(V_o\)</span>. Figure <a href="#fig:population-density">9</a> shows that our estimate of <span class="math inline">\(V_o\)</span> corresponds very closely to the one reported in the paper (Figure 3 in <span class="citation" data-cites="koen_examining_2013"><a href="#ref-koen_examining_2013" role="doc-biblioref">Koen et al.</a> (<a href="#ref-koen_examining_2013" role="doc-biblioref">2013</a>)</span>).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://mc-stan.org/bayesplot/reference/MCMC-intervals.html'>mcmc_areas</a></span><span class='op'>(</span><span class='va'>samples</span>, point_est <span class='op'>=</span> <span class='st'>"mean"</span>, prob <span class='op'>=</span> <span class='fl'>.8</span><span class='op'>)</span>
</code></pre>
</div>
<div class="figure" style="text-align: center"><span id="fig:population-density"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/population-density-1.png" alt="Density plots of UVSDT model's Population-level Effects' posterior distributions. Different parameters are indicated on the y-axis, and possible values on the x-axis. Vertical lines are posterior means, and shaded areas are 80\% credible intervals." width="624" />
<p class="caption">
Figure 9: Density plots of UVSDT model’s Population-level Effects’ posterior distributions. Different parameters are indicated on the y-axis, and possible values on the x-axis. Vertical lines are posterior means, and shaded areas are 80% credible intervals.
</p>
</div>
</div>
<h4 id="heterogeneity-parameters">Heterogeneity parameters</h4>
<p>Although the “population-level estimates,” which perhaps should be called “average effects,” are usually the main target of inference, they are not the whole story, nor are they necessarily the most interesting part of it. It has been firmly established that, when allowed to vary, the standard deviation of the signal distribution is greater than 1. However, the between-subject variability of this parameter has received less interest. Figure <a href="#fig:population-density2">10</a> reveals that the between-subject heterogeneity of <em>a</em> is quite large: The subject-specific effects have a standard deviation around .5.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>samples_h</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/posterior_samples.brmsfit.html'>posterior_samples</a></span><span class='op'>(</span><span class='va'>fit</span>, <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"sd_"</span>, <span class='st'>"cor_"</span><span class='op'>)</span><span class='op'>)</span>
<span class='fu'><a href='https://mc-stan.org/bayesplot/reference/MCMC-intervals.html'>mcmc_areas</a></span><span class='op'>(</span><span class='va'>samples_h</span>, point_est <span class='op'>=</span> <span class='st'>"mean"</span>, prob <span class='op'>=</span> <span class='fl'>.8</span><span class='op'>)</span>
</code></pre>
</div>
<div class="figure" style="text-align: center"><span id="fig:population-density2"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/population-density2-1.png" alt="Density plots of the standard deviation and correlation parameters of the UVSDT model's parameters. Parameter's appended with 'sd_id__' are between-id standard deviations, ones with 'cor_id__' are between-id correlations." width="624" />
<p class="caption">
Figure 10: Density plots of the standard deviation and correlation parameters of the UVSDT model’s parameters. Parameter’s appended with ’sd_id__’ are between-id standard deviations, ones with ’cor_id__’ are between-id correlations.
</p>
</div>
</div>
<p>Figure <a href="#fig:population-density2">10</a> also tells us that the subject-specific <em>d’</em>s and <em>a</em>s are correlated ("cor_id__isold__disc_isold"). We can further investigate this relationship by plotting the subject specific signal-SDs and <em>d’</em>s side by side:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:side-by-side"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/side-by-side-1.png" alt="Ridgeline plot of posterior distributions of subject-specific standard deviations (left) and d-primes (right). The ordering of subjects on the y-axis is the same, so as to highlight the relationship between the two variables." width="624" />
<p class="caption">
Figure 11: Ridgeline plot of posterior distributions of subject-specific standard deviations (left) and d-primes (right). The ordering of subjects on the y-axis is the same, so as to highlight the relationship between the two variables.
</p>
</div>
</div>
<p>As can be seen in the ridgeline plots <span class="citation" data-cites="wilke_ggridges:_2017">(<a href="#ref-wilke_ggridges:_2017" role="doc-biblioref">Wilke 2017</a>)</span> in Figure <a href="#fig:side-by-side">11</a>, participants with greater <span class="math inline">\(\sigma_{signal}\)</span> tend to have greater d’: Increase in recognition sensitivity is accompanied with an increase in the signal distribution’s variability. The density plots also make it clear that we are much less certain about individuals whose values (either one) are greater, as shown by the spread out posterior distributions. Yet another way to visualize this relationship is with a scatterplot of the posterior means Figure <a href="#fig:scatterplot">12</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:scatterplot"></span>
<img src="2017-10-09-bayesian-estimation-of-signal-detection-theory-models_files/figure-html5/scatterplot-1.png" alt="Scatterplot of posterior means of subject-specific d-primes and signal distribution standard deviations." width="624" />
<p class="caption">
Figure 12: Scatterplot of posterior means of subject-specific d-primes and signal distribution standard deviations.
</p>
</div>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>Estimating EVSDT and UVSDT models in the Bayesian framework with the brms package <span class="citation" data-cites="burkner_brms:_2017">(<a href="#ref-burkner_brms:_2017" role="doc-biblioref">Bürkner 2017b</a>)</span> is both easy (relatively speaking) and informative. In this post, we estimated a hierarchical nonlinear cognitive model using no more than a few lines of code. Previous literature on the topic (e.g. <span class="citation" data-cites="rouder_signal_2007"><a href="#ref-rouder_signal_2007" role="doc-biblioref">Rouder et al.</a> (<a href="#ref-rouder_signal_2007" role="doc-biblioref">2007</a>)</span>) has focused on simpler (EVSDT) models with more complicated implementations–hopefully in this post I have shown that these models are within the reach of a greater audience, provided that they have some familiarity with R.</p>
<p>Another point worth making is a more general one about hierarchical models: We know that participants introduce (random) variation in our models. Ignoring this variation is clearly not good <span class="citation" data-cites="estes_problem_1956">(<a href="#ref-estes_problem_1956" role="doc-biblioref">Estes 1956</a>)</span>. It is more appropriate to model this variability, and use the resulting parameters to draw inference about the heterogeneity in parameters (and more generally, cognitive strategies) across individuals. Although maximum likelihood methods provide (noisy) point estimates of what I’ve here called between-subject heterogeneity parameters, the Bayesian method allows drawing firm conclusions about these parameters.</p>
<!-- Include at end of document -->
<h3 class="appendix" id="support-this-work">Support this work</h3>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="vuorre" data-color="#34A5DA" data-emoji=""  data-font="Lato" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>
<div class="sourceCode" id="cb14"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<h3 class="appendix" id="software-used">Software used</h3>
<p>The following software packages were used: R [Version 4.0.3; <span class="citation" data-cites="R-base"><a href="#ref-R-base" role="doc-biblioref">R Core Team</a> (<a href="#ref-R-base" role="doc-biblioref">2020</a>)</span>] and the R-packages <em>bayesplot</em> [Version 1.8.0; <span class="citation" data-cites="R-bayesplot"><a href="#ref-R-bayesplot" role="doc-biblioref">Gabry et al.</a> (<a href="#ref-R-bayesplot" role="doc-biblioref">2019</a>)</span>], <em>boot</em> [Version 1.3.27; <span class="citation" data-cites="R-boot"><a href="#ref-R-boot" role="doc-biblioref">Davison and Hinkley</a> (<a href="#ref-R-boot" role="doc-biblioref">1997</a>)</span>], <em>brms</em> [Version 2.14.4; <span class="citation" data-cites="R-brms_a"><a href="#ref-R-brms_a" role="doc-biblioref">Bürkner</a> (<a href="#ref-R-brms_a" role="doc-biblioref">2017a</a>)</span>; <span class="citation" data-cites="R-brms_b"><a href="#ref-R-brms_b" role="doc-biblioref">Bürkner</a> (<a href="#ref-R-brms_b" role="doc-biblioref">2018</a>)</span>], <em>dplyr</em> [Version 1.0.4; <span class="citation" data-cites="R-dplyr"><a href="#ref-R-dplyr" role="doc-biblioref">Wickham et al.</a> (<a href="#ref-R-dplyr" role="doc-biblioref">2021</a>)</span>], <em>forcats</em> [Version 0.5.1; <span class="citation" data-cites="R-forcats"><a href="#ref-R-forcats" role="doc-biblioref">Wickham</a> (<a href="#ref-R-forcats" role="doc-biblioref">2021a</a>)</span>], <em>ggplot2</em> [Version 3.3.3; <span class="citation" data-cites="R-ggplot2"><a href="#ref-R-ggplot2" role="doc-biblioref">Wickham</a> (<a href="#ref-R-ggplot2" role="doc-biblioref">2016</a>)</span>], <em>ggridges</em> [Version 0.5.3; <span class="citation" data-cites="R-ggridges"><a href="#ref-R-ggridges" role="doc-biblioref">Wilke</a> (<a href="#ref-R-ggridges" role="doc-biblioref">2021</a>)</span>], <em>knitr</em> [Version 1.31; <span class="citation" data-cites="R-knitr"><a href="#ref-R-knitr" role="doc-biblioref">Xie</a> (<a href="#ref-R-knitr" role="doc-biblioref">2015</a>)</span>], <em>lme4</em> [Version 1.1.26; <span class="citation" data-cites="R-lme4"><a href="#ref-R-lme4" role="doc-biblioref">Bates et al.</a> (<a href="#ref-R-lme4" role="doc-biblioref">2015</a>)</span>], <em>Matrix</em> [Version 1.3.2; <span class="citation" data-cites="R-Matrix"><a href="#ref-R-Matrix" role="doc-biblioref">Bates and Maechler</a> (<a href="#ref-R-Matrix" role="doc-biblioref">2021</a>)</span>], <em>purrr</em> [Version 0.3.4; <span class="citation" data-cites="R-purrr"><a href="#ref-R-purrr" role="doc-biblioref">Henry and Wickham</a> (<a href="#ref-R-purrr" role="doc-biblioref">2020</a>)</span>], <em>Rcpp</em> [Version 1.0.6; <span class="citation" data-cites="R-Rcpp_a"><a href="#ref-R-Rcpp_a" role="doc-biblioref">Eddelbuettel and François</a> (<a href="#ref-R-Rcpp_a" role="doc-biblioref">2011</a>)</span>; <span class="citation" data-cites="R-Rcpp_b"><a href="#ref-R-Rcpp_b" role="doc-biblioref">Eddelbuettel and Balamuta</a> (<a href="#ref-R-Rcpp_b" role="doc-biblioref">2018</a>)</span>], <em>readr</em> [Version 1.4.0; <span class="citation" data-cites="R-readr"><a href="#ref-R-readr" role="doc-biblioref">Wickham and Hester</a> (<a href="#ref-R-readr" role="doc-biblioref">2020</a>)</span>], <em>scales</em> [Version 1.1.1; <span class="citation" data-cites="R-scales"><a href="#ref-R-scales" role="doc-biblioref">Wickham and Seidel</a> (<a href="#ref-R-scales" role="doc-biblioref">2020</a>)</span>], <em>sdtalt</em> [Version 1.3; <span class="citation" data-cites="R-sdtalt"><a href="#ref-R-sdtalt" role="doc-biblioref">Wright</a> (<a href="#ref-R-sdtalt" role="doc-biblioref">2011b</a>)</span>], <em>stringr</em> [Version 1.4.0; <span class="citation" data-cites="R-stringr"><a href="#ref-R-stringr" role="doc-biblioref">Wickham</a> (<a href="#ref-R-stringr" role="doc-biblioref">2019</a>)</span>], <em>tibble</em> [Version 3.1.0; <span class="citation" data-cites="R-tibble"><a href="#ref-R-tibble" role="doc-biblioref">Müller and Wickham</a> (<a href="#ref-R-tibble" role="doc-biblioref">2021</a>)</span>], <em>tidyr</em> [Version 1.1.3; <span class="citation" data-cites="R-tidyr"><a href="#ref-R-tidyr" role="doc-biblioref">Wickham</a> (<a href="#ref-R-tidyr" role="doc-biblioref">2021b</a>)</span>], <em>tidyverse</em> [Version 1.3.0; <span class="citation" data-cites="R-tidyverse"><a href="#ref-R-tidyverse" role="doc-biblioref">Wickham et al.</a> (<a href="#ref-R-tidyverse" role="doc-biblioref">2019</a>)</span>], <em>viridis</em> [Version 0.5.1; <span class="citation" data-cites="R-viridis"><a href="#ref-R-viridis" role="doc-biblioref">Garnier</a> (<a href="#ref-R-viridis" role="doc-biblioref">2018a</a>)</span>; <span class="citation" data-cites="R-viridisLite"><a href="#ref-R-viridisLite" role="doc-biblioref">Garnier</a> (<a href="#ref-R-viridisLite" role="doc-biblioref">2018b</a>)</span>], and <em>viridisLite</em> [Version 0.3.0; <span class="citation" data-cites="R-viridisLite"><a href="#ref-R-viridisLite" role="doc-biblioref">Garnier</a> (<a href="#ref-R-viridisLite" role="doc-biblioref">2018b</a>)</span>].</p>
<!-- Include at end of document -->
<div class="sourceCode" id="cb15"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-R-Matrix" class="csl-entry" role="doc-biblioentry">
Bates, Douglas, and Martin Maechler. 2021. <em>Matrix: Sparse and Dense Matrix Classes and Methods</em>. <a href="https://CRAN.R-project.org/package=Matrix">https://CRAN.R-project.org/package=Matrix</a>.
</div>
<div id="ref-R-lme4" class="csl-entry" role="doc-biblioentry">
Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. <span>“Fitting Linear Mixed-Effects Models Using <span class="nocase">lme4</span>.”</span> <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-bolger_intensive_2013" class="csl-entry" role="doc-biblioentry">
Bolger, Niall, and Jean-Philippe Laurenceau. 2013. <em>Intensive Longitudinal Methods: An Introduction to Diary and Experience Sampling Research</em>. Guilford Press. <a href="http://www.intensivelongitudinal.com/">http://www.intensivelongitudinal.com/</a>.
</div>
<div id="ref-R-brms_a" class="csl-entry" role="doc-biblioentry">
Bürkner, Paul-Christian. 2017a. <span>“<span class="nocase">brms</span>: An <span>R</span> Package for <span>Bayesian</span> Multilevel Models Using <span>Stan</span>.”</span> <em>Journal of Statistical Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.
</div>
<div id="ref-burkner_brms:_2017" class="csl-entry" role="doc-biblioentry">
———. 2017b. <span>“Brms: <span>An R Package</span> for <span>Bayesian Multilevel Models Using Stan</span>.”</span> <em>Journal of Statistical Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.
</div>
<div id="ref-R-brms_b" class="csl-entry" role="doc-biblioentry">
———. 2018. <span>“Advanced <span>Bayesian</span> Multilevel Modeling with the <span>R</span> Package <span class="nocase">brms</span>.”</span> <em>The R Journal</em> 10 (1): 395–411. <a href="https://doi.org/10.32614/RJ-2018-017">https://doi.org/10.32614/RJ-2018-017</a>.
</div>
<div id="ref-R-boot" class="csl-entry" role="doc-biblioentry">
Davison, A. C., and D. V. Hinkley. 1997. <em>Bootstrap Methods and Their Applications</em>. Cambridge: Cambridge University Press. <a href="http://statwww.epfl.ch/davison/BMA/">http://statwww.epfl.ch/davison/BMA/</a>.
</div>
<div id="ref-decarlo_using_2003" class="csl-entry" role="doc-biblioentry">
Decarlo, Lawrence T. 2003. <span>“Using the <span>PLUM</span> Procedure of <span>SPSS</span> to Fit Unequal Variance and Generalized Signal Detection Models.”</span> <em>Behavior Research Methods, Instruments, &amp; Computers</em> 35 (1): 49–56. <a href="https://doi.org/10.3758/BF03195496">https://doi.org/10.3758/BF03195496</a>.
</div>
<div id="ref-decarlo_signal_1998" class="csl-entry" role="doc-biblioentry">
DeCarlo, Lawrence T. 1998. <span>“Signal Detection Theory and Generalized Linear Models.”</span> <em>Psychological Methods</em> 3 (2): 186–205. <a href="https://doi.org/10.1037/1082-989X.3.2.186">https://doi.org/10.1037/1082-989X.3.2.186</a>.
</div>
<div id="ref-decarlo_statistical_2010" class="csl-entry" role="doc-biblioentry">
———. 2010. <span>“On the Statistical and Theoretical Basis of Signal Detection Theory and Extensions: <span>Unequal</span> Variance, Random Coefficient, and Mixture Models.”</span> <em>Journal of Mathematical Psychology</em> 54 (3): 304–13. <a href="https://doi.org/10.1016/j.jmp.2010.01.001">https://doi.org/10.1016/j.jmp.2010.01.001</a>.
</div>
<div id="ref-R-Rcpp_b" class="csl-entry" role="doc-biblioentry">
Eddelbuettel, Dirk, and James Joseph Balamuta. 2018. <span>“<span class="nocase">Extending extit<span>R</span> with extit<span>C++</span>: A Brief Introduction to extit<span>Rcpp</span></span>.”</span> <em>The American Statistician</em> 72 (1): 28–36. <a href="https://doi.org/10.1080/00031305.2017.1375990">https://doi.org/10.1080/00031305.2017.1375990</a>.
</div>
<div id="ref-R-Rcpp_a" class="csl-entry" role="doc-biblioentry">
Eddelbuettel, Dirk, and Romain François. 2011. <span>“<span>Rcpp</span>: Seamless <span>R</span> and <span>C++</span> Integration.”</span> <em>Journal of Statistical Software</em> 40 (8): 1–18. <a href="https://doi.org/10.18637/jss.v040.i08">https://doi.org/10.18637/jss.v040.i08</a>.
</div>
<div id="ref-estes_problem_1956" class="csl-entry" role="doc-biblioentry">
Estes, W. K. 1956. <span>“The Problem of Inference from Curves Based on Group Data.”</span> <em>Psychological Bulletin</em> 53 (2): 134–40. <a href="https://doi.org/10.1037/h0045156">https://doi.org/10.1037/h0045156</a>.
</div>
<div id="ref-gabry_bayesplot:_2017" class="csl-entry" role="doc-biblioentry">
Gabry, Jonah. 2017. <em>Bayesplot: <span>Plotting</span> for <span>Bayesian</span> Models</em>. <a href="http://mc-stan.org/">http://mc-stan.org/</a>.
</div>
<div id="ref-R-bayesplot" class="csl-entry" role="doc-biblioentry">
Gabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. 2019. <span>“Visualization in Bayesian Workflow.”</span> <em>J. R. Stat. Soc. A</em> 182: 389–402. <a href="https://doi.org/10.1111/rssa.12378">https://doi.org/10.1111/rssa.12378</a>.
</div>
<div id="ref-R-viridis" class="csl-entry" role="doc-biblioentry">
Garnier, Simon. 2018a. <em>Viridis: Default Color Maps from ’Matplotlib’</em>. <a href="https://CRAN.R-project.org/package=viridis">https://CRAN.R-project.org/package=viridis</a>.
</div>
<div id="ref-R-viridisLite" class="csl-entry" role="doc-biblioentry">
———. 2018b. <em>viridisLite: Default Color Maps from ’Matplotlib’ (Lite Version)</em>. <a href="https://CRAN.R-project.org/package=viridisLite">https://CRAN.R-project.org/package=viridisLite</a>.
</div>
<div id="ref-gelman_data_2007" class="csl-entry" role="doc-biblioentry">
Gelman, Andrew, and Jennifer Hill. 2007. <em>Data <span>Analysis Using Regression</span> and <span>Multilevel</span>/<span>Hierarchical Models</span></em>. <span>Cambridge University Press</span>.
</div>
<div id="ref-R-purrr" class="csl-entry" role="doc-biblioentry">
Henry, Lionel, and Hadley Wickham. 2020. <em>Purrr: Functional Programming Tools</em>. <a href="https://CRAN.R-project.org/package=purrr">https://CRAN.R-project.org/package=purrr</a>.
</div>
<div id="ref-koen_examining_2013" class="csl-entry" role="doc-biblioentry">
Koen, Joshua D., Mariam Aly, Wei-Chun Wang, and Andrew P. Yonelinas. 2013. <span>“Examining the Causes of Memory Strength Variability: <span>Recollection</span>, Attention Failure, or Encoding Variability?”</span> <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 39 (6): 1726–41. <a href="https://doi.org/10.1037/a0033671">https://doi.org/10.1037/a0033671</a>.
</div>
<div id="ref-kruschke_doing_2014" class="csl-entry" role="doc-biblioentry">
Kruschke, John K. 2014. <em>Doing Bayesian Data Analysis: A Tutorial Introduction with r</em>. 2nd Edition. Burlington, <span>MA</span>: Academic Press.
</div>
<div id="ref-macmillan_detection_2005" class="csl-entry" role="doc-biblioentry">
Macmillan, Neil A., and C. Douglas Creelman. 2005. <em>Detection Theory: A User’s Guide</em>. 2nd ed. <span>Mahwah, N.J</span>: <span>Lawrence Erlbaum Associates</span>.
</div>
<div id="ref-mcelreath_statistical_2016" class="csl-entry" role="doc-biblioentry">
McElreath, Richard. 2016. <em>Statistical Rethinking: A Bayesian Course with Examples in r and Stan</em>. <span>CRC</span> Press.
</div>
<div id="ref-R-tibble" class="csl-entry" role="doc-biblioentry">
Müller, Kirill, and Hadley Wickham. 2021. <em>Tibble: Simple Data Frames</em>. <a href="https://CRAN.R-project.org/package=tibble">https://CRAN.R-project.org/package=tibble</a>.
</div>
<div id="ref-r_core_team_r:_2017" class="csl-entry" role="doc-biblioentry">
R Core Team. 2017. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-R-base" class="csl-entry" role="doc-biblioentry">
———. 2020. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-rouder_introduction_2005" class="csl-entry" role="doc-biblioentry">
Rouder, Jeffrey N., and Jun Lu. 2005. <span>“An Introduction to <span>Bayesian</span> Hierarchical Models with an Application in the Theory of Signal Detection.”</span> <em>Psychonomic Bulletin &amp; Review</em> 12 (4): 573–604. <a href="https://doi.org/10.3758/BF03196750">https://doi.org/10.3758/BF03196750</a>.
</div>
<div id="ref-rouder_signal_2007" class="csl-entry" role="doc-biblioentry">
Rouder, Jeffrey N., Jun Lu, Dongchu Sun, Paul Speckman, Richard D. Morey, and Moshe Naveh-Benjamin. 2007. <span>“Signal <span>Detection Models</span> with <span>Random Participant</span> and <span>Item Effects</span>.”</span> <em>Psychometrika</em> 72 (4): 621–42. <a href="https://doi.org/10.1007/s11336-005-1350-6">https://doi.org/10.1007/s11336-005-1350-6</a>.
</div>
<div id="ref-singmann_mptinr:_2013" class="csl-entry" role="doc-biblioentry">
Singmann, Henrik, and David Kellen. 2013. <span>“<span>MPTinR</span>: <span>Analysis</span> of Multinomial Processing Tree Models in <span>R</span>.”</span> <em>Behavior Research Methods</em> 45 (2): 560–75. <a href="https://doi.org/10.3758/s13428-012-0259-0">https://doi.org/10.3758/s13428-012-0259-0</a>.
</div>
<div id="ref-skagerberg_manipulating_2008" class="csl-entry" role="doc-biblioentry">
Skagerberg, Elin M., and Daniel B. Wright. 2008. <span>“Manipulating Power Can Affect Memory Conformity.”</span> <em>Applied Cognitive Psychology</em> 22 (2): 207–16. <a href="https://doi.org/10.1002/acp.1353">https://doi.org/10.1002/acp.1353</a>.
</div>
<div id="ref-stan_development_team_rstan:_2016" class="csl-entry" role="doc-biblioentry">
Stan Development Team. 2016a. <em><span>RStan</span>: The r Interface to Stan</em>. <a href="http://mc-stan.org/">http://mc-stan.org/</a>.
</div>
<div id="ref-stan_development_team_stan:_2016" class="csl-entry" role="doc-biblioentry">
———. 2016b. <em>Stan: A c++ Library for Probability and Sampling, Version 2.15.0</em>. <a href="http://mc-stan.org/">http://mc-stan.org/</a>.
</div>
<div id="ref-stanislaw_calculation_1999" class="csl-entry" role="doc-biblioentry">
Stanislaw, Harold, and Natasha Todorov. 1999. <span>“Calculation of Signal Detection Theory Measures.”</span> <em>Behavior Research Methods, Instruments, &amp; Computers</em> 31 (1): 137–49. <a href="http://link.springer.com/article/10.3758/BF03207704">http://link.springer.com/article/10.3758/BF03207704</a>.
</div>
<div id="ref-ravenzwaaij_simple_2016" class="csl-entry" role="doc-biblioentry">
van Ravenzwaaij, Don, Pete Cassey, and Scott D. Brown. 2016. <span>“A Simple Introduction to <span>Markov Chain Monte</span>–<span>Carlo</span> Sampling.”</span> <em>Psychonomic Bulletin &amp; Review</em>, March, 1–12. <a href="https://doi.org/10.3758/s13423-016-1015-8">https://doi.org/10.3758/s13423-016-1015-8</a>.
</div>
<div id="ref-R-ggplot2" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-R-stringr" class="csl-entry" role="doc-biblioentry">
———. 2019. <em>Stringr: Simple, Consistent Wrappers for Common String Operations</em>. <a href="https://CRAN.R-project.org/package=stringr">https://CRAN.R-project.org/package=stringr</a>.
</div>
<div id="ref-R-forcats" class="csl-entry" role="doc-biblioentry">
———. 2021a. <em>Forcats: Tools for Working with Categorical Variables (Factors)</em>. <a href="https://CRAN.R-project.org/package=forcats">https://CRAN.R-project.org/package=forcats</a>.
</div>
<div id="ref-R-tidyr" class="csl-entry" role="doc-biblioentry">
———. 2021b. <em>Tidyr: Tidy Messy Data</em>. <a href="https://CRAN.R-project.org/package=tidyr">https://CRAN.R-project.org/package=tidyr</a>.
</div>
<div id="ref-R-tidyverse" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the <span class="nocase">tidyverse</span>.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
<div id="ref-R-dplyr" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2021. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.
</div>
<div id="ref-R-readr" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley, and Jim Hester. 2020. <em>Readr: Read Rectangular Text Data</em>. <a href="https://CRAN.R-project.org/package=readr">https://CRAN.R-project.org/package=readr</a>.
</div>
<div id="ref-R-scales" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley, and Dana Seidel. 2020. <em>Scales: Scale Functions for Visualization</em>. <a href="https://CRAN.R-project.org/package=scales">https://CRAN.R-project.org/package=scales</a>.
</div>
<div id="ref-wilke_ggridges:_2017" class="csl-entry" role="doc-biblioentry">
Wilke, Claus O. 2017. <em>Ggridges: <span>Ridgeline Plots</span> in ’Ggplot2’</em>. <a href="https://CRAN.R-project.org/package=ggridges">https://CRAN.R-project.org/package=ggridges</a>.
</div>
<div id="ref-R-ggridges" class="csl-entry" role="doc-biblioentry">
———. 2021. <em>Ggridges: Ridgeline Plots in ’Ggplot2’</em>. <a href="https://CRAN.R-project.org/package=ggridges">https://CRAN.R-project.org/package=ggridges</a>.
</div>
<div id="ref-wright_sdtalt:_2011" class="csl-entry" role="doc-biblioentry">
Wright, Daniel B. 2011a. <em>Sdtalt: <span>Signal</span> Detection Theory and Alternatives</em>. <a href="https://CRAN.R-project.org/package=sdtalt">https://CRAN.R-project.org/package=sdtalt</a>.
</div>
<div id="ref-R-sdtalt" class="csl-entry" role="doc-biblioentry">
———. 2011b. <em>Sdtalt: Signal Detection Theory and Alternatives</em>. <a href="https://CRAN.R-project.org/package=sdtalt">https://CRAN.R-project.org/package=sdtalt</a>.
</div>
<div id="ref-R-knitr" class="csl-entry" role="doc-biblioentry">
Xie, Yihui. 2015. <em>Dynamic Documents with <span>R</span> and Knitr</em>. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. <a href="https://yihui.org/knitr/">https://yihui.org/knitr/</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Hierarchical regression is sometimes used to mean the practice of adding predictors to a regression model based on the predictors’ <em>p</em>-values. Whatever you do, don’t do that.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The label “Group-Level Effects” might be slightly confusing because the SD and correlation parameters describe the population of subject-specific effects. I have yet to find a 100% satisfactory terminology here, but think that brms’ terminology is certainly less confusing than that of “random” and “fixed” effects, traditionally encountered in multilevel modeling literature.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Recall that intercepts are automatically included, but can be explicitly included by adding <code>1</code> to the formula’s right hand side.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><code>0 + ...</code> removes the model’s intercept.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="updates-and-corrections">Corrections</h3>
  <p>If you see mistakes or want to suggest changes, please <a href="https://github.com/mvuorre/mvuorre.github.io/issues/new">create an issue</a> on the source repository.</p>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. Source code is available at <a href="https://github.com/mvuorre/mvuorre.github.io">https://github.com/mvuorre/mvuorre.github.io</a>, unless otherwise noted. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Vuorre (2017, Oct. 9). Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models. Retrieved from https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{vuorre2017bayesian,
  author = {Vuorre, Matti},
  title = {Statistics and Data Science Tutorials: Bayesian Estimation of Signal Detection Models},
  url = {https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/},
  year = {2017}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
